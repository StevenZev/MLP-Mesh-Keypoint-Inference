{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc010216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b84a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24fb5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guitar.json\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "model_id_to_keypoints = {}\n",
    "for entry in annotations:\n",
    "    model_id = entry['model_id']\n",
    "    keypoints = [kp['xyz'] for kp in entry['keypoints']]\n",
    "    keypoints = np.array(keypoints, dtype=np.float32)\n",
    "    model_id_to_keypoints[model_id] = keypoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0609f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using minimal PointNet (not full PointNet++)\n",
    "class PointNetKeypointRegressor(nn.Module):\n",
    "    def __init__(self, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.sa1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_keypoints * 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, 3]\n",
    "        x = x.permute(0, 2, 1)  # [B, 3, N]\n",
    "        x = self.sa1(x)  # [B, 1024, N]\n",
    "        x = torch.max(x, 2)[0]  # [B, 1024]\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, NUM_KEYPOINTS, 3)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeNetKeypointDataset(Dataset):\n",
    "    def __init__(self, mesh_dir, annotation_json):\n",
    "        self.mesh_dir = mesh_dir\n",
    "        self.samples = []\n",
    "\n",
    "        #count_valid = 0\n",
    "        #count_total = 0\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotation_json) as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        for entry in annotations:\n",
    "            model_id = entry['model_id']\n",
    "            #print(model_id)\n",
    "            keypoints = np.array([kp['xyz'] for kp in entry['keypoints']], dtype=np.float32)\n",
    "            #count_total += 1\n",
    "            if keypoints.shape[0] != NUM_KEYPOINTS:\n",
    "                continue  # Strictly filter only 6-keypoint meshes\n",
    "            self.samples.append((model_id, keypoints))\n",
    "            #count_valid += 1\n",
    "\n",
    "        #print(f\"Total meshes: {count_total}, Valid 6-keypoint meshes: {count_valid}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_id, keypoints = self.samples[idx]\n",
    "\n",
    "        #print(\"Inside __getitem__: keypoints.shape =\", keypoints.shape) \n",
    "\n",
    "        mesh_path = os.path.join(self.mesh_dir, model_id + \".ply\")\n",
    "\n",
    "        try:\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "            if points.shape[0] < NUM_POINTS:\n",
    "                pad_size = NUM_POINTS - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {model_id}: {e}\")\n",
    "            points = np.zeros((NUM_POINTS, 3), dtype=np.float32)\n",
    "            keypoints = np.zeros((NUM_KEYPOINTS, 3), dtype=np.float32)\n",
    "\n",
    "        # Normalize\n",
    "        #print(\"Points Min:\", np.min(points), \"Max:\", np.max(points))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        points = (points - centroid) / scale\n",
    "        keypoints = (keypoints - centroid) / scale\n",
    "\n",
    "\n",
    "        return torch.from_numpy(points).float(), torch.from_numpy(keypoints).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca84ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 4096 #Maybe do 512\n",
    "NUM_KEYPOINTS = 9 # 2 meshes have 5 keypoints idk why\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc4b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 587\n",
      "Resuming training from epoch 45\n",
      "First batch - Input shape: torch.Size([128, 4096, 3]), Target shape: torch.Size([128, 9, 3])\n",
      "First batch loss: 0.001150\n",
      "Pred range: [-0.816, 1.070]\n",
      "Target range: [-0.831, 1.008]\n",
      "Epoch 46/95 - Loss: 0.000974\n",
      "Epoch 47/95 - Loss: 0.000977\n",
      "Epoch 48/95 - Loss: 0.000943\n",
      "Epoch 49/95 - Loss: 0.000963\n",
      "Epoch 50/95 - Loss: 0.000947\n",
      "Epoch 51/95 - Loss: 0.000884\n",
      "Epoch 52/95 - Loss: 0.000897\n",
      "Epoch 53/95 - Loss: 0.000903\n",
      "Epoch 54/95 - Loss: 0.000859\n",
      "Saved checkpoint: train_checkpoints/guitarnet_epoch_55.pth\n",
      "Epoch 55/95 - Loss: 0.000909\n",
      "Epoch 56/95 - Loss: 0.000975\n",
      "Epoch 57/95 - Loss: 0.000906\n",
      "Epoch 58/95 - Loss: 0.000824\n",
      "Epoch 59/95 - Loss: 0.000783\n",
      "Epoch 60/95 - Loss: 0.000766\n",
      "Epoch 61/95 - Loss: 0.000803\n",
      "Epoch 62/95 - Loss: 0.000760\n",
      "Epoch 63/95 - Loss: 0.000781\n",
      "Epoch 64/95 - Loss: 0.000728\n",
      "Saved checkpoint: train_checkpoints/guitarnet_epoch_65.pth\n",
      "Epoch 65/95 - Loss: 0.000745\n",
      "Epoch 66/95 - Loss: 0.000768\n",
      "Epoch 67/95 - Loss: 0.001082\n",
      "Epoch 68/95 - Loss: 0.001025\n",
      "Epoch 69/95 - Loss: 0.000975\n",
      "Epoch 70/95 - Loss: 0.000875\n",
      "Epoch 71/95 - Loss: 0.000935\n",
      "Epoch 72/95 - Loss: 0.000902\n",
      "Epoch 73/95 - Loss: 0.000851\n",
      "Epoch 74/95 - Loss: 0.000775\n",
      "Saved checkpoint: train_checkpoints/guitarnet_epoch_75.pth\n",
      "Epoch 75/95 - Loss: 0.000769\n",
      "Epoch 76/95 - Loss: 0.000773\n",
      "Epoch 77/95 - Loss: 0.000817\n",
      "Epoch 78/95 - Loss: 0.000757\n",
      "Epoch 79/95 - Loss: 0.000739\n",
      "Epoch 80/95 - Loss: 0.000685\n",
      "Epoch 81/95 - Loss: 0.000692\n",
      "Epoch 82/95 - Loss: 0.000711\n",
      "Epoch 83/95 - Loss: 0.000663\n",
      "Epoch 84/95 - Loss: 0.000760\n",
      "Saved checkpoint: train_checkpoints/guitarnet_epoch_85.pth\n",
      "Epoch 85/95 - Loss: 0.000672\n",
      "Epoch 86/95 - Loss: 0.000671\n",
      "Epoch 87/95 - Loss: 0.000815\n",
      "Epoch 88/95 - Loss: 0.000763\n",
      "Epoch 89/95 - Loss: 0.001058\n",
      "Epoch 90/95 - Loss: 0.000933\n",
      "Epoch 91/95 - Loss: 0.000874\n",
      "Epoch 92/95 - Loss: 0.000778\n",
      "Epoch 93/95 - Loss: 0.000757\n",
      "Epoch 94/95 - Loss: 0.000822\n",
      "Saved checkpoint: train_checkpoints/guitarnet_epoch_95.pth\n",
      "Epoch 95/95 - Loss: 0.000910\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "dataset = ShapeNetKeypointDataset(mesh_dir=\"Guitars\", annotation_json=\"guitar.json\")  \n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "model = PointNetKeypointRegressor(NUM_KEYPOINTS).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "os.makedirs(\"train_checkpoints\", exist_ok=True)\n",
    "\n",
    "resume_checkpoint_path = \"saved_models/guitarnet_final.pth\"\n",
    "resume_checkpoint_path = \"train_checkpoints/guitarnet_epoch_45.pth\"\n",
    "if os.path.exists(resume_checkpoint_path):\n",
    "    checkpoint = torch.load(resume_checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "total_epoch = 50 # Additional epochs to train \n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_idx, (pts, kps) in enumerate(dataloader):\n",
    "        try:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            preds = model(pts)\n",
    "            loss = F.mse_loss(preds, kps)\n",
    "            \n",
    "            # Back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            if epoch == 0 and batch_idx == 0:\n",
    "                print(f\"First batch - Input shape: {pts.shape}, Target shape: {kps.shape}\")\n",
    "                print(f\"First batch loss: {loss.item():.6f}\")\n",
    "                print(f\"Pred range: [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "                print(f\"Target range: [{kps.min():.3f}, {kps.max():.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Average loss\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = f\"train_checkpoints/guitarnet_epoch_{start_epoch + epoch+1}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': start_epoch + epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+ start_epoch + 1}/{start_epoch + total_epoch} - Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': avg_loss,\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet_final_2.pth\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': avg_loss,\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet_final_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "45a407c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Full checkpoint: saved_models/capnet_keypoint_model_20250620_125801.pth\n",
      "Model only: saved_models/capnet_keypoint_model_20250620_125801_model_only.pth\n",
      "Info file: saved_models/capnet_keypoint_model_20250620_125801_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('saved_models/capnet_keypoint_model_20250620_125801.pth',\n",
       " 'saved_models/capnet_keypoint_model_20250620_125801_model_only.pth',\n",
       " 'saved_models/capnet_keypoint_model_20250620_125801_info.json')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_complete(model, optimizer, epoch, loss, save_dir=\"saved_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e70b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7c61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path):\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create model with same architecture\n",
    "    model = PointNetKeypointRegressor(NUM_KEYPOINTS)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded! Trained for {checkpoint['epoch']+1} epochs, final loss: {checkpoint['loss']:.6f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "474c6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    \"\"\"Predict keypoints for a single cap .ply file\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    try:\n",
    "        # Load and process mesh (same as your training preprocessing)\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "        \n",
    "        # Sample points\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "        \n",
    "        # Normalize (exactly like training)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        \n",
    "        # Denormalize keypoints back to original scale\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "        \n",
    "        return original_keypoints, normalized_keypoints\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f391077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(model, ply_folder):\n",
    "    \"\"\"Predict keypoints for all .ply files in a folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    ply_files = [os.path.join(ply_folder, f) for f in os.listdir(ply_folder) if f.endswith('.ply')]\n",
    "    print(f\"Found {len(ply_files)} .ply files\")\n",
    "    \n",
    "    for ply_file in ply_files:\n",
    "        print(f\"Processing {os.path.basename(ply_file)}...\")\n",
    "        keypoints, normalized_kp = predict_cap_keypoints(model, ply_file)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            results[os.path.basename(ply_file)] = {\n",
    "                'original_keypoints': keypoints,\n",
    "                'normalized_keypoints': normalized_kp\n",
    "            }\n",
    "            print(f\"  Success! Predicted {len(keypoints)} keypoints\")\n",
    "        else:\n",
    "            print(f\"  Failed to process {ply_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bd33cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! Trained for 32 epochs, final loss: 0.001158\n"
     ]
    }
   ],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a96318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted keypoints:\n",
      "  Keypoint 1: [-0.005, 0.345, 0.030]\n",
      "  Keypoint 2: [0.001, -0.181, 0.000]\n",
      "  Keypoint 3: [0.099, -0.168, 0.018]\n",
      "  Keypoint 4: [-0.108, -0.169, 0.023]\n",
      "  Keypoint 5: [0.153, -0.557, 0.023]\n",
      "  Keypoint 6: [-0.138, -0.552, 0.031]\n",
      "  Keypoint 7: [-0.012, -0.456, -0.006]\n",
      "  Keypoint 8: [0.081, -0.336, 0.017]\n",
      "  Keypoint 9: [-0.079, -0.325, 0.018]\n"
     ]
    }
   ],
   "source": [
    "keypoints, norm_kp = predict_keypoints(model, \"a7dd.ply\")\n",
    "if keypoints is not None:\n",
    "    print(\"Predicted keypoints:\")\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        print(f\"  Keypoint {i+1}: [{kp[0]:.3f}, {kp[1]:.3f}, {kp[2]:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd69dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_wsl",
   "language": "python",
   "name": "capnet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
