{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc010216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from datetime import datetime \n",
    "\n",
    "from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
    "from pointnet2_keypoint_regressor import get_model\n",
    "\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b84a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24fb5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guitar.json\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "model_id_to_keypoints = {}\n",
    "for entry in annotations:\n",
    "    model_id = entry['model_id']\n",
    "    keypoints = [kp['xyz'] for kp in entry['keypoints']]\n",
    "    keypoints = np.array(keypoints, dtype=np.float32)\n",
    "    model_id_to_keypoints[model_id] = keypoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0609f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using minimal PointNet (not full PointNet++)\n",
    "class PointNetKeypointRegressor(nn.Module):\n",
    "    def __init__(self, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.sa1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_keypoints * 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, 3]\n",
    "        x = x.permute(0, 2, 1)  # [B, 3, N]\n",
    "        x = self.sa1(x)  # [B, 1024, N]\n",
    "        x = torch.max(x, 2)[0]  # [B, 1024]\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, NUM_KEYPOINTS, 3)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca84ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1024 # Minimum 512 for input, ~1000 for neighborhood density; 2^14 = 16384\n",
    "NUM_KEYPOINTS = 9 # 2 meshes have 5 keypoints idk why\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeNetKeypointDataset(Dataset):\n",
    "    def __init__(self, mesh_dir, annotation_json):\n",
    "        self.mesh_dir = mesh_dir\n",
    "        self.samples = []\n",
    "\n",
    "        #count_valid = 0\n",
    "        #count_total = 0\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotation_json) as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        for entry in annotations:\n",
    "            model_id = entry['model_id']\n",
    "            #print(model_id)\n",
    "            keypoints = np.array([kp['xyz'] for kp in entry['keypoints']], dtype=np.float32)\n",
    "            #count_total += 1\n",
    "            if keypoints.shape[0] != NUM_KEYPOINTS:\n",
    "                continue  # Strictly filter only 6-keypoint meshes\n",
    "            self.samples.append((model_id, keypoints))\n",
    "            #count_valid += 1\n",
    "\n",
    "        #print(f\"Total meshes: {count_total}, Valid 6-keypoint meshes: {count_valid}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_id, keypoints = self.samples[idx]\n",
    "\n",
    "        #print(\"Inside __getitem__: keypoints.shape =\", keypoints.shape) \n",
    "\n",
    "        mesh_path = os.path.join(self.mesh_dir, model_id + \".ply\")\n",
    "\n",
    "        try:\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "            if points.shape[0] < NUM_POINTS:\n",
    "                pad_size = NUM_POINTS - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {model_id}: {e}\")\n",
    "            points = np.zeros((NUM_POINTS, 3), dtype=np.float32)\n",
    "            keypoints = np.zeros((NUM_KEYPOINTS, 3), dtype=np.float32)\n",
    "\n",
    "        # Normalize\n",
    "        #print(\"Points Min:\", np.min(points), \"Max:\", np.max(points))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        points = (points - centroid) / scale\n",
    "        keypoints = (keypoints - centroid) / scale\n",
    "\n",
    "\n",
    "        return torch.from_numpy(points).float(), torch.from_numpy(keypoints).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc4b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2935\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#model = PointNetKeypointRegressor(NUM_KEYPOINTS).to(device)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_KEYPOINTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m     27\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:31\u001b[0m, in \u001b[0;36mget_model.__init__\u001b[0;34m(self, num_class, normal_channel)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#self.drop2 = nn.Dropout(0.5) #Same here >> 0.3\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[43mnum_keypoints\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "dataset = ShapeNetKeypointDataset(mesh_dir=\"Guitars/9_Augmented\", annotation_json=\"guitar_9_augmented.json\")  \n",
    "\n",
    "total_size = len(dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "#model = PointNetKeypointRegressor(NUM_KEYPOINTS).to(device)\n",
    "model = get_model(num_class=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "if False: # For resuming.\n",
    "    os.makedirs(\"train_checkpoints\", exist_ok=True)\n",
    "\n",
    "    #resume_checkpoint_path = \"saved_models/guitarnet_final.pth\"\n",
    "    resume_checkpoint_path = \"train_checkpoints/guitarnet++_epoch_50.pth\"\n",
    "    if os.path.exists(resume_checkpoint_path):\n",
    "        checkpoint = torch.load(resume_checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        val_losses = checkpoint.get('val_losses', [])\n",
    "\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "total_epoch = 50 # Additional epochs to train \n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    #num_batches = 0\n",
    "    \n",
    "    for batch_idx, (pts, kps) in enumerate(train_loader):\n",
    "        try:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0, 2, 1) #Permute to fit input size\n",
    "            \n",
    "            # Forward pass\n",
    "            preds = model(pts)\n",
    "            loss = F.mse_loss(preds, kps)\n",
    "            #loss = nn.MSELoss() # Not sure why this one is better tbh\n",
    "            \n",
    "            # Back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_train_loss += loss.item()\n",
    "            #num_batches += 1\n",
    "            \n",
    "            if epoch == 0 and batch_idx == 0:\n",
    "                print(f\"First batch - Input shape: {pts.shape}, Target shape: {kps.shape}\")\n",
    "                print(f\"First batch loss: {loss.item():.6f}\")\n",
    "                print(f\"Pred range: [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "                print(f\"Target range: [{kps.min():.3f}, {kps.max():.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Average train loss\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for pts, kps in val_loader:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0,2,1)\n",
    "            preds = model(pts)\n",
    "            val_loss = F.mse_loss(preds, kps)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss/len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    if epoch + start_epoch + 1 == 30:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 1e-4\n",
    "        print(\"Reduced LR to 1e-4\")\n",
    "    if False: #For checkpointing\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = f\"train_checkpoints/guitarnet++_3_epoch_{start_epoch + epoch+1}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': start_epoch + epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+ start_epoch + 1}/{start_epoch + total_epoch}\\nTrain Loss: {avg_train_loss:.6f}; Validation Loss: {avg_val_loss:.6f}\")\n",
    "if False: #For save when done\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': avg_train_loss,\n",
    "        'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "    }, \"saved_models/guitarnet++_3_final.pth\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d909c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:31\u001b[0m, in \u001b[0;36mget_model.__init__\u001b[0;34m(self, num_class, normal_channel)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#self.drop2 = nn.Dropout(0.5) #Same here >> 0.3\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[43mnum_keypoints\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_keypoints' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6421fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45cf500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': avg_loss,\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet++_epoch_12.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e70b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d7c61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path):\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create model with same architecture\n",
    "    model = get_model(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded! Trained for {checkpoint['epoch']+1} epochs, final loss: {checkpoint['loss']:.6f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    \"\"\"Predict keypoints for a single cap .ply file\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    try:\n",
    "        # Load and process mesh (same as your training preprocessing)\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "        \n",
    "        # Sample points\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "        \n",
    "        # Normalize (exactly like training)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        \n",
    "        # Denormalize keypoints back to original scale\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "        \n",
    "        return original_keypoints, normalized_keypoints\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b7a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    try:\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "\n",
    "        return original_keypoints, normalized_keypoints\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f391077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(model, ply_folder):\n",
    "    \"\"\"Predict keypoints for all .ply files in a folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    ply_files = [os.path.join(ply_folder, f) for f in os.listdir(ply_folder) if f.endswith('.ply')]\n",
    "    print(f\"Found {len(ply_files)} .ply files\")\n",
    "    \n",
    "    for ply_file in ply_files:\n",
    "        print(f\"Processing {os.path.basename(ply_file)}...\")\n",
    "        keypoints, normalized_kp = predict_cap_keypoints(model, ply_file)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            results[os.path.basename(ply_file)] = {\n",
    "                'original_keypoints': keypoints,\n",
    "                'normalized_keypoints': normalized_kp\n",
    "            }\n",
    "            print(f\"  Success! Predicted {len(keypoints)} keypoints\")\n",
    "        else:\n",
    "            print(f\"  Failed to process {ply_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a18aace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! Trained for 50 epochs, final loss: 0.004393\n"
     ]
    }
   ],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5a96318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010 0.354 0.010\n",
      "0.012 -0.211 -0.001\n",
      "0.107 -0.164 0.013\n",
      "-0.086 -0.198 0.010\n",
      "0.125 -0.490 0.009\n",
      "-0.095 -0.488 0.019\n",
      "0.010 -0.514 0.009\n",
      "0.099 -0.321 0.012\n",
      "-0.078 -0.331 0.007\n"
     ]
    }
   ],
   "source": [
    "keypoints, norm_kp = predict_keypoints(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")\n",
    "if keypoints is not None:\n",
    "    #print(\"Predicted keypoints:\")\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        print(f\"{kp[0]:.3f} {kp[1]:.3f} {kp[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40413345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
