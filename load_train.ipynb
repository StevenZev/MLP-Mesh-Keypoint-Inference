{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc010216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from datetime import datetime \n",
    "\n",
    "from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
    "from pointnet2_keypoint_regressor import get_model#, get_model_msg\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b84a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24fb5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guitar.json\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "model_id_to_keypoints = {}\n",
    "for entry in annotations:\n",
    "    model_id = entry['model_id']\n",
    "    keypoints = [kp['xyz'] for kp in entry['keypoints']]\n",
    "    keypoints = np.array(keypoints, dtype=np.float32)\n",
    "    model_id_to_keypoints[model_id] = keypoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0609f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using minimal PointNet (not full PointNet++)\n",
    "class PointNetKeypointRegressor(nn.Module):\n",
    "    def __init__(self, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.sa1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_keypoints * 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, 3]\n",
    "        x = x.permute(0, 2, 1)  # [B, 3, N]\n",
    "        x = self.sa1(x)  # [B, 1024, N]\n",
    "        x = torch.max(x, 2)[0]  # [B, 1024]\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, NUM_KEYPOINTS, 3)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeNetKeypointDataset(Dataset):\n",
    "    def __init__(self, mesh_dir, annotation_json):\n",
    "        self.mesh_dir = mesh_dir\n",
    "        self.samples = []\n",
    "\n",
    "        #count_valid = 0\n",
    "        #count_total = 0\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotation_json) as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        for entry in annotations:\n",
    "            model_id = entry['model_id']\n",
    "            #print(model_id)\n",
    "            keypoints = np.array([kp['xyz'] for kp in entry['keypoints']], dtype=np.float32)\n",
    "            #count_total += 1\n",
    "            if keypoints.shape[0] != NUM_KEYPOINTS:\n",
    "                continue  # Strictly filter only 6-keypoint meshes\n",
    "            self.samples.append((model_id, keypoints))\n",
    "            #count_valid += 1\n",
    "\n",
    "        #print(f\"Total meshes: {count_total}, Valid 6-keypoint meshes: {count_valid}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_id, keypoints = self.samples[idx]\n",
    "\n",
    "        #print(\"Inside __getitem__: keypoints.shape =\", keypoints.shape) \n",
    "\n",
    "        mesh_path = os.path.join(self.mesh_dir, model_id + \".ply\")\n",
    "\n",
    "        try:\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "            if points.shape[0] < NUM_POINTS:\n",
    "                pad_size = NUM_POINTS - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {model_id}: {e}\")\n",
    "            points = np.zeros((NUM_POINTS, 3), dtype=np.float32)\n",
    "            keypoints = np.zeros((NUM_KEYPOINTS, 3), dtype=np.float32)\n",
    "\n",
    "        # Normalize\n",
    "        #print(\"Points Min:\", np.min(points), \"Max:\", np.max(points))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        points = (points - centroid) / scale\n",
    "        keypoints = (keypoints - centroid) / scale\n",
    "\n",
    "\n",
    "        return torch.from_numpy(points).float(), torch.from_numpy(keypoints).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff21819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca84ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1024 # Minimum 512 for input, ~1000 for neighborhood density; 2^14 = 16384\n",
    "NUM_KEYPOINTS = 9 # 2 meshes have 5 keypoints idk why\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc4b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 2348\n",
      "Test dataset size: 587\n",
      "Pred range: [-0.562, 0.643]\n",
      "Target range: [-1.006, 1.010]\n",
      "Epoch 1/50\n",
      "Train Loss: 0.061864; Validation Loss: 0.078836\n",
      "Pred range: [-1.589, 1.309]\n",
      "Target range: [-1.019, 1.024]\n",
      "Epoch 2/50\n",
      "Train Loss: 0.009446; Validation Loss: 0.076760\n",
      "Pred range: [-1.165, 1.176]\n",
      "Target range: [-1.004, 1.019]\n",
      "Epoch 3/50\n",
      "Train Loss: 0.005098; Validation Loss: 0.078935\n",
      "Pred range: [-1.122, 1.128]\n",
      "Target range: [-1.008, 1.017]\n",
      "Epoch 4/50\n",
      "Train Loss: 0.004269; Validation Loss: 0.006506\n",
      "Pred range: [-1.094, 1.233]\n",
      "Target range: [-1.000, 1.026]\n",
      "Epoch 5/50\n",
      "Train Loss: 0.004929; Validation Loss: 0.003952\n",
      "Pred range: [-1.178, 1.042]\n",
      "Target range: [-1.002, 1.058]\n",
      "Epoch 6/50\n",
      "Train Loss: 0.003864; Validation Loss: 0.003656\n",
      "Pred range: [-0.999, 0.992]\n",
      "Target range: [-1.014, 1.022]\n",
      "Epoch 7/50\n",
      "Train Loss: 0.003378; Validation Loss: 0.003265\n",
      "Pred range: [-1.072, 1.074]\n",
      "Target range: [-1.008, 1.045]\n",
      "Epoch 8/50\n",
      "Train Loss: 0.003724; Validation Loss: 0.003114\n",
      "Pred range: [-1.088, 1.071]\n",
      "Target range: [-1.013, 1.026]\n",
      "Epoch 9/50\n",
      "Train Loss: 0.002975; Validation Loss: 0.002911\n",
      "Pred range: [-1.053, 1.068]\n",
      "Target range: [-1.022, 1.021]\n",
      "Epoch 10/50\n",
      "Train Loss: 0.002698; Validation Loss: 0.002819\n",
      "Pred range: [-1.038, 1.025]\n",
      "Target range: [-1.018, 1.032]\n",
      "Epoch 11/50\n",
      "Train Loss: 0.002806; Validation Loss: 0.002766\n",
      "Pred range: [-1.075, 1.186]\n",
      "Target range: [-1.019, 1.018]\n",
      "Epoch 12/50\n",
      "Train Loss: 0.002781; Validation Loss: 0.002678\n",
      "Pred range: [-1.039, 1.033]\n",
      "Target range: [-1.004, 1.031]\n",
      "Epoch 13/50\n",
      "Train Loss: 0.002526; Validation Loss: 0.002437\n",
      "Pred range: [-1.024, 1.039]\n",
      "Target range: [-1.025, 1.021]\n",
      "Epoch 14/50\n",
      "Train Loss: 0.002303; Validation Loss: 0.002407\n",
      "Pred range: [-1.026, 1.028]\n",
      "Target range: [-1.008, 1.017]\n",
      "Epoch 15/50\n",
      "Train Loss: 0.002410; Validation Loss: 0.002418\n",
      "Pred range: [-1.092, 1.073]\n",
      "Target range: [-1.013, 1.023]\n",
      "Epoch 16/50\n",
      "Train Loss: 0.002153; Validation Loss: 0.002246\n",
      "Pred range: [-1.116, 1.033]\n",
      "Target range: [-1.016, 1.020]\n",
      "Epoch 17/50\n",
      "Train Loss: 0.001964; Validation Loss: 0.002272\n",
      "Pred range: [-0.990, 1.086]\n",
      "Target range: [-1.022, 1.038]\n",
      "Epoch 18/50\n",
      "Train Loss: 0.001854; Validation Loss: 0.002143\n",
      "Pred range: [-1.033, 0.986]\n",
      "Target range: [-1.002, 1.022]\n",
      "Epoch 19/50\n",
      "Train Loss: 0.001919; Validation Loss: 0.002829\n",
      "Pred range: [-1.141, 1.018]\n",
      "Target range: [-1.000, 1.020]\n",
      "Epoch 20/50\n",
      "Train Loss: 0.001836; Validation Loss: 0.001893\n",
      "Pred range: [-1.007, 1.028]\n",
      "Target range: [-1.004, 1.010]\n",
      "Epoch 21/50\n",
      "Train Loss: 0.001693; Validation Loss: 0.002058\n",
      "Pred range: [-1.099, 1.047]\n",
      "Target range: [-1.002, 1.020]\n",
      "Epoch 22/50\n",
      "Train Loss: 0.001674; Validation Loss: 0.001857\n",
      "Pred range: [-1.136, 1.124]\n",
      "Target range: [-1.005, 1.023]\n",
      "Epoch 23/50\n",
      "Train Loss: 0.001685; Validation Loss: 0.001791\n",
      "Pred range: [-1.051, 1.009]\n",
      "Target range: [-1.016, 1.060]\n",
      "Epoch 24/50\n",
      "Train Loss: 0.001621; Validation Loss: 0.001819\n",
      "Pred range: [-1.094, 1.138]\n",
      "Target range: [-1.010, 1.023]\n",
      "Epoch 25/50\n",
      "Train Loss: 0.001770; Validation Loss: 0.001839\n",
      "Pred range: [-1.138, 1.078]\n",
      "Target range: [-1.008, 1.012]\n",
      "Epoch 26/50\n",
      "Train Loss: 0.001791; Validation Loss: 0.001787\n",
      "Pred range: [-0.999, 1.056]\n",
      "Target range: [-1.019, 1.013]\n",
      "Epoch 27/50\n",
      "Train Loss: 0.001661; Validation Loss: 0.001774\n",
      "Pred range: [-1.119, 1.036]\n",
      "Target range: [-1.001, 1.032]\n",
      "Epoch 28/50\n",
      "Train Loss: 0.001615; Validation Loss: 0.001776\n",
      "Pred range: [-1.008, 1.036]\n",
      "Target range: [-1.012, 1.016]\n",
      "Epoch 29/50\n",
      "Train Loss: 0.001461; Validation Loss: 0.001715\n",
      "Pred range: [-1.021, 1.090]\n",
      "Target range: [-1.012, 1.022]\n",
      "Epoch 30/50\n",
      "Train Loss: 0.001470; Validation Loss: 0.001538\n",
      "Pred range: [-1.047, 1.090]\n",
      "Target range: [-1.005, 1.017]\n",
      "Epoch 31/50\n",
      "Train Loss: 0.001395; Validation Loss: 0.001664\n",
      "Pred range: [-1.076, 1.011]\n",
      "Target range: [-1.013, 1.010]\n",
      "Epoch 32/50\n",
      "Train Loss: 0.001466; Validation Loss: 0.001562\n",
      "Pred range: [-1.068, 1.029]\n",
      "Target range: [-1.010, 1.021]\n",
      "Epoch 33/50\n",
      "Train Loss: 0.001473; Validation Loss: 0.001551\n",
      "Pred range: [-1.048, 1.053]\n",
      "Target range: [-1.014, 1.015]\n",
      "Epoch 34/50\n",
      "Train Loss: 0.001384; Validation Loss: 0.001462\n",
      "Pred range: [-1.091, 1.050]\n",
      "Target range: [-1.002, 1.014]\n",
      "Epoch 35/50\n",
      "Train Loss: 0.001225; Validation Loss: 0.001497\n",
      "Pred range: [-1.013, 1.031]\n",
      "Target range: [-1.010, 1.027]\n",
      "Epoch 36/50\n",
      "Train Loss: 0.001209; Validation Loss: 0.001517\n",
      "Pred range: [-1.083, 1.131]\n",
      "Target range: [-1.011, 1.027]\n",
      "Epoch 37/50\n",
      "Train Loss: 0.001290; Validation Loss: 0.001573\n",
      "Pred range: [-1.025, 1.072]\n",
      "Target range: [-1.015, 1.014]\n",
      "Epoch 38/50\n",
      "Train Loss: 0.001380; Validation Loss: 0.001592\n",
      "Pred range: [-1.092, 1.055]\n",
      "Target range: [-1.024, 1.015]\n",
      "Epoch 39/50\n",
      "Train Loss: 0.001383; Validation Loss: 0.001867\n",
      "Pred range: [-1.127, 0.955]\n",
      "Target range: [-1.033, 1.024]\n",
      "Epoch 40/50\n",
      "Train Loss: 0.001426; Validation Loss: 0.001694\n",
      "Pred range: [-0.971, 1.060]\n",
      "Target range: [-1.005, 1.011]\n",
      "Epoch 41/50\n",
      "Train Loss: 0.001285; Validation Loss: 0.001520\n",
      "Pred range: [-1.072, 0.991]\n",
      "Target range: [-1.003, 1.050]\n",
      "Epoch 42/50\n",
      "Train Loss: 0.001344; Validation Loss: 0.001655\n",
      "Pred range: [-0.992, 1.077]\n",
      "Target range: [-1.002, 1.022]\n",
      "Epoch 43/50\n",
      "Train Loss: 0.001341; Validation Loss: 0.001684\n",
      "Pred range: [-1.005, 1.017]\n",
      "Target range: [-1.001, 1.016]\n",
      "Epoch 44/50\n",
      "Train Loss: 0.001169; Validation Loss: 0.001585\n",
      "Pred range: [-1.093, 1.061]\n",
      "Target range: [-1.015, 1.026]\n",
      "Epoch 45/50\n",
      "Train Loss: 0.001126; Validation Loss: 0.001376\n",
      "Pred range: [-1.046, 1.072]\n",
      "Target range: [-1.018, 1.016]\n",
      "Epoch 46/50\n",
      "Train Loss: 0.001085; Validation Loss: 0.001497\n",
      "Pred range: [-1.030, 1.035]\n",
      "Target range: [-1.013, 1.010]\n",
      "Epoch 47/50\n",
      "Train Loss: 0.001149; Validation Loss: 0.001403\n",
      "Pred range: [-1.073, 1.015]\n",
      "Target range: [-0.996, 1.018]\n",
      "Epoch 48/50\n",
      "Train Loss: 0.001242; Validation Loss: 0.001517\n",
      "Pred range: [-1.104, 1.076]\n",
      "Target range: [-1.011, 1.016]\n",
      "Epoch 49/50\n",
      "Train Loss: 0.001293; Validation Loss: 0.001450\n",
      "Pred range: [-0.980, 1.054]\n",
      "Target range: [-1.013, 1.012]\n",
      "Epoch 50/50\n",
      "Train Loss: 0.001085; Validation Loss: 0.001489\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "dataset = ShapeNetKeypointDataset(mesh_dir=\"Guitars/9_Augmented\", annotation_json=\"guitar_9_augmented.json\")  \n",
    "\n",
    "total_size = len(dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(val_dataset)}\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "#model = PointNetKeypointRegressor(NUM_KEYPOINTS).to(device)\n",
    "model = get_model(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "if False: # For resuming.\n",
    "    os.makedirs(\"train_checkpoints\", exist_ok=True)\n",
    "\n",
    "    #resume_checkpoint_path = \"saved_models/guitarnet_final.pth\"\n",
    "    resume_checkpoint_path = \"train_checkpoints/guitarnet++_epoch_50.pth\"\n",
    "    if os.path.exists(resume_checkpoint_path):\n",
    "        checkpoint = torch.load(resume_checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        val_losses = checkpoint.get('val_losses', [])\n",
    "\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "total_epoch = 50 # Additional epochs to train \n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    #num_batches = 0\n",
    "    \n",
    "    for batch_idx, (pts, kps) in enumerate(train_loader):\n",
    "        try:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0, 2, 1) #Permute to fit input size\n",
    "            \n",
    "            # Forward pass\n",
    "            preds, _ = model(pts)\n",
    "            loss = F.mse_loss(preds, kps)\n",
    "            #loss = nn.MSELoss() # Not sure why this one is better tbh\n",
    "            \n",
    "            # Back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_train_loss += loss.item()\n",
    "            #num_batches += 1\n",
    "            \n",
    "            #if epoch == 0 and batch_idx == 0:\n",
    "            if batch_idx == 0:\n",
    "                #print(f\"First batch - Input shape: {pts.shape}, Target shape: {kps.shape}\")\n",
    "                #print(f\"First batch loss: {loss.item():.6f}\")\n",
    "                print(f\"Pred range: [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "                print(f\"Target range: [{kps.min():.3f}, {kps.max():.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Average train loss\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for pts, kps in val_loader:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0,2,1)\n",
    "            preds, _ = model(pts)\n",
    "            val_loss = F.mse_loss(preds, kps)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss/len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    if True:\n",
    "        if epoch + start_epoch + 1 % 5 == 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.8\n",
    "                print(\"Force-reduced LR to 80%\")\n",
    "\n",
    "    if False:\n",
    "        if epoch + start_epoch + 1 == 20:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 1e-4\n",
    "            print(\"Reduced LR to 1e-4\")\n",
    "    if False: #For checkpointing\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = f\"train_checkpoints/guitarnet++_lin_3_epoch_{start_epoch + epoch+1}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': start_epoch + epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+ start_epoch + 1}/{start_epoch + total_epoch}\\nTrain Loss: {avg_train_loss:.6f}; Validation Loss: {avg_val_loss:.6f}\")\n",
    "if False: #For save when done\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': avg_train_loss,\n",
    "        'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "    }, \"saved_models/guitarnet++_lin_3_final.pth\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d909c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:31\u001b[0m, in \u001b[0;36mget_model.__init__\u001b[0;34m(self, num_class, normal_channel)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#self.drop2 = nn.Dropout(0.5) #Same here >> 0.3\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[43mnum_keypoints\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Train dataset size: 2348\n",
    "Test dataset size: 587\n",
    "First batch - Input shape: torch.Size([256, 3, 1024]), Target shape: torch.Size([256, 9, 3])\n",
    "First batch loss: 0.288146\n",
    "Pred range: [-1.969, 1.959]\n",
    "Target range: [-1.001, 1.021]\n",
    "Epoch 1/50\n",
    "Train Loss: 0.150820; Validation Loss: 0.103047\n",
    "Epoch 2/50\n",
    "Train Loss: 0.066115; Validation Loss: 0.124546\n",
    "Epoch 3/50\n",
    "Train Loss: 0.043645; Validation Loss: 0.078913\n",
    "Epoch 4/50\n",
    "Train Loss: 0.030031; Validation Loss: 0.087326\n",
    "Epoch 5/50\n",
    "Train Loss: 0.022437; Validation Loss: 0.085578\n",
    "Epoch 6/50\n",
    "Train Loss: 0.019087; Validation Loss: 0.046889\n",
    "Epoch 7/50\n",
    "Train Loss: 0.015242; Validation Loss: 0.013829\n",
    "Epoch 8/50\n",
    "Train Loss: 0.012592; Validation Loss: 0.006803\n",
    "Epoch 9/50\n",
    "Train Loss: 0.011893; Validation Loss: 0.005015\n",
    "Epoch 10/50\n",
    "Train Loss: 0.011156; Validation Loss: 0.009370\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6421fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cf500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': [avg_train_loss, avg_val_loss],\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet++_lin_4_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6e70b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_keypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_KEYPOINTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:62\u001b[0m, in \u001b[0;36mget_model_msg.__init__\u001b[0;34m(self, num_keypoints, normal_channel)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_keypoints, normal_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     63\u001b[0m     in_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normal_channel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_keypoints \u001b[38;5;241m=\u001b[39m num_keypoints\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = get_model_msg(num_keypoints=NUM_KEYPOINTS, normal_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d7c61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path):\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create model with same architecture\n",
    "    model = get_model(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    #model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    #print(f\"Model loaded! Trained for {checkpoint['epoch']+1} epochs, final loss: {checkpoint['loss'][0]:.6f}, {checkpoint['loss'][1]:.6f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5869abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "474c6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    \"\"\"Predict keypoints for a single cap .ply file\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    try:\n",
    "        # Load and process mesh (same as your training preprocessing)\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "        \n",
    "        # Sample points\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "        \n",
    "        # Normalize (exactly like training)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        \n",
    "        # Denormalize keypoints back to original scale\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "        \n",
    "        return original_keypoints, normalized_keypoints\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b7a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "   \n",
    "    mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "    if mesh.is_empty or len(mesh.faces) == 0:\n",
    "        raise ValueError(\"Empty mesh\")\n",
    "\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "    if points.shape[0] < NUM_POINTS:\n",
    "        pad_size = NUM_POINTS - points.shape[0]\n",
    "        pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "        points = np.vstack((points, pad))\n",
    "\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "    normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "\n",
    "    points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "    points_tensor = points_tensor.permute(0, 2, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        output = model(points_tensor)\n",
    "        normalized_keypoints = output[0].cpu().numpy().squeeze(0)\n",
    "        \n",
    "\n",
    "    original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "\n",
    "    return original_keypoints, normalized_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "592d83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints_no_normalization(model, ply_file_path):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    try:\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "\n",
    "        points_tensor = torch.from_numpy(points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_keypoints = model(points_tensor)[0].cpu().numpy().squeeze(0)\n",
    "\n",
    "        return predicted_keypoints, predicted_keypoints  # same, no normalization\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f391077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(model, ply_folder):\n",
    "    \"\"\"Predict keypoints for all .ply files in a folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    ply_files = [os.path.join(ply_folder, f) for f in os.listdir(ply_folder) if f.endswith('.ply')]\n",
    "    print(f\"Found {len(ply_files)} .ply files\")\n",
    "    \n",
    "    for ply_file in ply_files:\n",
    "        print(f\"Processing {os.path.basename(ply_file)}...\")\n",
    "        keypoints, normalized_kp = predict_keypoints(model, ply_file)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            results[os.path.basename(ply_file)] = {\n",
    "                'original_keypoints': keypoints,\n",
    "                'normalized_keypoints': normalized_kp\n",
    "            }\n",
    "            print(f\"  Success! Predicted {len(keypoints)} keypoints\")\n",
    "        else:\n",
    "            print(f\"  Failed to process {ply_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49173634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'tuple' object has no attribute 'cpu'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_keypoints_no_normalization(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a18aace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_2_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5a96318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.024 -0.234 0.012\n",
      "0.020 -0.227 0.003\n",
      "0.037 -0.202 0.002\n",
      "0.035 -0.208 0.046\n",
      "-0.018 -0.232 0.033\n",
      "0.015 -0.222 0.023\n",
      "-0.017 -0.235 -0.006\n",
      "-0.015 -0.241 0.039\n",
      "0.041 -0.233 -0.015\n"
     ]
    }
   ],
   "source": [
    "keypoints, norm_kp = predict_keypoints(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")\n",
    "if keypoints is not None:\n",
    "    #print(\"Predicted keypoints:\")\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        print(f\"{kp[0]:.3f} {kp[1]:.3f} {kp[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26eb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf273e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd10b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8826310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1024  # or match what you used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3d6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Load a .ply mesh, sample and normalize points, and predict keypoints using the trained model.\n",
    "    Returns: (N, 3) keypoint array in mesh coordinates\n",
    "    \"\"\"\n",
    "    # Load and check mesh\n",
    "    mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "    if mesh.is_empty or len(mesh.faces) == 0:\n",
    "        raise ValueError(\"Empty or invalid mesh.\")\n",
    "\n",
    "    # Sample surface points\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "    if points.shape[0] < NUM_POINTS:\n",
    "        pad_size = NUM_POINTS - points.shape[0]\n",
    "        pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "        points = np.vstack((points, pad))\n",
    "\n",
    "    # Normalize (same as training)\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "    normalized_points = (points - centroid) / scale\n",
    "\n",
    "    # Convert to model input\n",
    "    points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0)  # shape (1, N, 3)\n",
    "    points_tensor = points_tensor.permute(0, 2, 1).to(device)  # (B, 3, N)\n",
    "\n",
    "    # Predict\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        keypoints_normalized, _ = model(points_tensor)  # (1, K, 3)\n",
    "\n",
    "    keypoints_normalized = keypoints_normalized.squeeze(0).cpu().numpy()\n",
    "    keypoints = keypoints_normalized * scale + centroid  # restore original coordinates\n",
    "\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df572e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_lin_4_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132eefc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackedArray([[ 0.04513097, -0.19405351,  0.01136884],\n",
       "              [-0.02167698, -0.18845859, -0.00182964],\n",
       "              [ 0.00805703, -0.21001184, -0.00239157],\n",
       "              [ 0.03293498, -0.16253963,  0.03528798],\n",
       "              [ 0.04411637, -0.17960015, -0.02284026],\n",
       "              [-0.00692826, -0.20783013, -0.01440394],\n",
       "              [ 0.04791758, -0.2072043 , -0.00217193],\n",
       "              [ 0.03363895, -0.22034198,  0.03379551],\n",
       "              [-0.03213071, -0.23326143, -0.02353662]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_keypoints(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce605c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6da3a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointPredictor:\n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize the keypoint predictor\n",
    "        \n",
    "        Args:\n",
    "            model_path: path to saved model (.pth file)\n",
    "            device: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load model checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        self.config = checkpoint.get('config', {'num_keypoints': 9, 'num_points': 1024})\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = get_model(\n",
    "            num_keypoints=self.config['num_keypoints'], \n",
    "            normal_channel=False\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load trained weights\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"Loaded model with {self.config['num_keypoints']} keypoints\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def load_and_sample_mesh(self, mesh_path, num_points=None):\n",
    "        \"\"\"\n",
    "        Load mesh and sample points from surface\n",
    "        \n",
    "        Args:\n",
    "            mesh_path: path to mesh file (.ply, .obj, etc.)\n",
    "            num_points: number of points to sample (default: from config)\n",
    "        \n",
    "        Returns:\n",
    "            points: numpy array of shape (num_points, 3)\n",
    "        \"\"\"\n",
    "        if num_points is None:\n",
    "            num_points = self.config['num_points']\n",
    "        \n",
    "        try:\n",
    "            # Load mesh\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "            \n",
    "            # Sample points from surface\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "            \n",
    "            # Handle case where mesh has fewer faces than requested points\n",
    "            if points.shape[0] < num_points:\n",
    "                pad_size = num_points - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "            \n",
    "            return points.astype(np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {mesh_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def normalize_points(self, points):\n",
    "        \"\"\"\n",
    "        Normalize points using same method as training\n",
    "        \n",
    "        Args:\n",
    "            points: numpy array of shape (num_points, 3)\n",
    "        \n",
    "        Returns:\n",
    "            normalized_points: numpy array of shape (num_points, 3)\n",
    "            centroid: numpy array of shape (3,) - for denormalization\n",
    "            scale: float - for denormalization\n",
    "        \"\"\"\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if scale == 0:\n",
    "            scale = 1.0\n",
    "        \n",
    "        normalized_points = (points - centroid) / scale\n",
    "        return normalized_points, centroid, scale\n",
    "    \n",
    "    def denormalize_keypoints(self, keypoints, centroid, scale):\n",
    "        \"\"\"\n",
    "        Convert normalized keypoints back to original coordinate system\n",
    "        \n",
    "        Args:\n",
    "            keypoints: numpy array of shape (num_keypoints, 3)\n",
    "            centroid: numpy array of shape (3,)\n",
    "            scale: float\n",
    "        \n",
    "        Returns:\n",
    "            denormalized_keypoints: numpy array of shape (num_keypoints, 3)\n",
    "        \"\"\"\n",
    "        return keypoints * scale + centroid\n",
    "    \n",
    "    def predict_keypoints(self, mesh_path, return_normalized=False):\n",
    "        \"\"\"\n",
    "        Predict keypoints for a single mesh\n",
    "        \n",
    "        Args:\n",
    "            mesh_path: path to mesh file\n",
    "            return_normalized: if True, return keypoints in normalized coordinates\n",
    "        \n",
    "        Returns:\n",
    "            keypoints: numpy array of shape (num_keypoints, 3)\n",
    "            points: numpy array of shape (num_points, 3) - sampled points\n",
    "            metadata: dict with normalization info\n",
    "        \"\"\"\n",
    "        # Load and sample mesh\n",
    "        points = self.load_and_sample_mesh(mesh_path)\n",
    "        if points is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Normalize points\n",
    "        normalized_points, centroid, scale = self.normalize_points(points)\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float()\n",
    "        points_tensor = points_tensor.unsqueeze(0).permute(0, 2, 1).to(self.device)  # Shape: (1, 3, num_points)\n",
    "        \n",
    "        # Predict keypoints\n",
    "        with torch.no_grad():\n",
    "            predicted_keypoints, _ = self.model(points_tensor)\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        predicted_keypoints = predicted_keypoints.squeeze(0).cpu().numpy()  # Shape: (num_keypoints, 3)\n",
    "        \n",
    "        # Denormalize if requested\n",
    "        if not return_normalized:\n",
    "            predicted_keypoints = self.denormalize_keypoints(predicted_keypoints, centroid, scale)\n",
    "            points_for_vis = points  # Original points\n",
    "        else:\n",
    "            points_for_vis = normalized_points\n",
    "        \n",
    "        metadata = {\n",
    "            'centroid': centroid,\n",
    "            'scale': scale,\n",
    "            'mesh_path': mesh_path\n",
    "        }\n",
    "        \n",
    "        return predicted_keypoints, points_for_vis, metadata\n",
    "    \n",
    "    def predict_batch(self, mesh_paths, return_normalized=False):\n",
    "        \"\"\"\n",
    "        Predict keypoints for multiple meshes\n",
    "        \n",
    "        Args:\n",
    "            mesh_paths: list of paths to mesh files\n",
    "            return_normalized: if True, return keypoints in normalized coordinates\n",
    "        \n",
    "        Returns:\n",
    "            results: list of (keypoints, points, metadata) tuples\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for mesh_path in mesh_paths:\n",
    "            result = self.predict_keypoints(mesh_path, return_normalized)\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "def visualize_keypoints_3d(points, keypoints, title=\"Predicted Keypoints\", figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Visualize point cloud with predicted keypoints\n",
    "    \n",
    "    Args:\n",
    "        points: numpy array of shape (num_points, 3)\n",
    "        keypoints: numpy array of shape (num_keypoints, 3)\n",
    "        title: string\n",
    "        figsize: tuple for figure size\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot point cloud\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], \n",
    "               c='lightblue', alpha=0.6, s=1, label='Point Cloud')\n",
    "    \n",
    "    # Plot keypoints\n",
    "    ax.scatter(keypoints[:, 0], keypoints[:, 1], keypoints[:, 2], \n",
    "               c='red', s=100, label='Predicted Keypoints', marker='o')\n",
    "    \n",
    "    # Add keypoint numbers\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        ax.text(kp[0], kp[1], kp[2], f'  {i}', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    max_range = np.array([points[:, 0].max()-points[:, 0].min(),\n",
    "                         points[:, 1].max()-points[:, 1].min(),\n",
    "                         points[:, 2].max()-points[:, 2].min()]).max() / 2.0\n",
    "    mid_x = (points[:, 0].max()+points[:, 0].min()) * 0.5\n",
    "    mid_y = (points[:, 1].max()+points[:, 1].min()) * 0.5\n",
    "    mid_z = (points[:, 2].max()+points[:, 2].min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def save_keypoints_to_file(keypoints, output_path, mesh_path=None):\n",
    "    \"\"\"\n",
    "    Save keypoints to a text file\n",
    "    \n",
    "    Args:\n",
    "        keypoints: numpy array of shape (num_keypoints, 3)\n",
    "        output_path: path to save keypoints\n",
    "        mesh_path: original mesh path (for reference)\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        if mesh_path:\n",
    "            f.write(f\"# Keypoints for mesh: {mesh_path}\\n\")\n",
    "        f.write(f\"# Format: x y z\\n\")\n",
    "        f.write(f\"# Number of keypoints: {len(keypoints)}\\n\")\n",
    "        \n",
    "        for i, kp in enumerate(keypoints):\n",
    "            f.write(f\"{kp[0]:.6f} {kp[1]:.6f} {kp[2]:.6f}\\n\")\n",
    "    \n",
    "    print(f\"Keypoints saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "145b45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 9 keypoints\n",
      "Using device: cuda\n",
      "Predicted 9 keypoints for Guitars/9_points/1a680e3308f2aac544b2fa2cac0778f5.ply\n",
      "Keypoints coordinates:\n",
      "  Keypoint 0: (0.021, 0.358, 0.008)\n",
      "  Keypoint 1: (0.005, -0.122, 0.001)\n",
      "  Keypoint 2: (0.098, -0.130, 0.030)\n",
      "  Keypoint 3: (-0.107, -0.148, 0.025)\n",
      "  Keypoint 4: (0.120, -0.495, 0.031)\n",
      "  Keypoint 5: (-0.127, -0.499, 0.028)\n",
      "  Keypoint 6: (-0.011, -0.541, 0.028)\n",
      "  Keypoint 7: (0.092, -0.252, 0.028)\n",
      "  Keypoint 8: (-0.100, -0.258, 0.034)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Keypoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkp[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkp[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkp[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Visualize results\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mvisualize_keypoints_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKeypoints for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save keypoints to file\u001b[39;00m\n\u001b[1;32m     17\u001b[0m output_path \u001b[38;5;241m=\u001b[39m mesh_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ply\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_keypoints.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 174\u001b[0m, in \u001b[0;36mvisualize_keypoints_3d\u001b[0;34m(points, keypoints, title, figsize)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvisualize_keypoints_3d\u001b[39m(points, keypoints, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Keypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m)):\n\u001b[1;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    Visualize point cloud with predicted keypoints\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m        figsize: tuple for figure size\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[1;32m    175\u001b[0m     ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[38;5;241m111\u001b[39m, projection\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Plot point cloud\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = KeypointPredictor(\"saved_models/guitarnet++_lin_4_final.pth\")\n",
    "\n",
    "# Predict keypoints for a single mesh\n",
    "mesh_path = \"Guitars/9_points/1a680e3308f2aac544b2fa2cac0778f5.ply\" \n",
    "keypoints, points, metadata = predictor.predict_keypoints(mesh_path)\n",
    "\n",
    "if keypoints is not None:\n",
    "    print(f\"Predicted {len(keypoints)} keypoints for {mesh_path}\")\n",
    "    print(\"Keypoints coordinates:\")\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        print(f\"  Keypoint {i}: ({kp[0]:.3f}, {kp[1]:.3f}, {kp[2]:.3f})\")\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_keypoints_3d(points, keypoints, f\"Keypoints for {os.path.basename(mesh_path)}\")\n",
    "    \n",
    "    # Save keypoints to file\n",
    "    output_path = mesh_path.replace('.ply', '_keypoints.txt')\n",
    "    save_keypoints_to_file(keypoints, output_path, mesh_path)\n",
    "else:\n",
    "    print(f\"Failed to process {mesh_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Batch prediction\n",
    "def example_batch_prediction():\n",
    "    predictor = KeypointPredictor(\"saved_models/guitarnet++_lin_4_final.pth\")\n",
    "    \n",
    "    # List of mesh files to process\n",
    "    mesh_directory = \"path/to/mesh/directory\"  # Replace with actual directory\n",
    "    mesh_files = [f for f in os.listdir(mesh_directory) if f.endswith('.ply')]\n",
    "    mesh_paths = [os.path.join(mesh_directory, f) for f in mesh_files[:5]]  # Process first 5\n",
    "    \n",
    "    # Predict for all meshes\n",
    "    results = predictor.predict_batch(mesh_paths)\n",
    "    \n",
    "    for i, (keypoints, points, metadata) in enumerate(results):\n",
    "        if keypoints is not None:\n",
    "            print(f\"Mesh {i+1}: {os.path.basename(metadata['mesh_path'])}\")\n",
    "            print(f\"  Predicted {len(keypoints)} keypoints\")\n",
    "            \n",
    "            # Visualize (optional - comment out if too many meshes)\n",
    "            if i < 3:  # Only show first 3\n",
    "                visualize_keypoints_3d(points, keypoints, f\"Mesh {i+1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d1d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Interactive prediction function\n",
    "def predict_and_visualize(mesh_path, model_path=\"saved_models/guitarnet++_lin_4_final.pth\"):\n",
    "    \"\"\"\n",
    "    Convenient function to predict and visualize keypoints for any mesh\n",
    "    \n",
    "    Args:\n",
    "        mesh_path: path to mesh file\n",
    "        model_path: path to trained model\n",
    "    \"\"\"\n",
    "    predictor = KeypointPredictor(model_path)\n",
    "    keypoints, points, metadata = predictor.predict_keypoints(mesh_path)\n",
    "    \n",
    "    if keypoints is not None:\n",
    "        print(f\"Successfully predicted keypoints for {os.path.basename(mesh_path)}\")\n",
    "        visualize_keypoints_3d(points, keypoints, f\"Keypoints: {os.path.basename(mesh_path)}\")\n",
    "        return keypoints, points, metadata\n",
    "    else:\n",
    "        print(f\"Failed to process {mesh_path}\")\n",
    "        return None, None, None\n",
    "\n",
    "# ===== RUN EXAMPLES =====\n",
    "# Uncomment the lines below to test:\n",
    "\n",
    "# Example usage - replace with your actual mesh path:\n",
    "# keypoints, points, metadata = predict_and_visualize(\"path/to/your/guitar.ply\")\n",
    "\n",
    "# Or use the more detailed examples:\n",
    "# example_single_prediction()\n",
    "# example_batch_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789aa41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
