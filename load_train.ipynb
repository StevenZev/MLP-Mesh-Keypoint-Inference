{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc010216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from datetime import datetime \n",
    "\n",
    "from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
    "from pointnet2_keypoint_regressor import get_model, get_model_msg\n",
    "\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b84a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24fb5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guitar.json\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "model_id_to_keypoints = {}\n",
    "for entry in annotations:\n",
    "    model_id = entry['model_id']\n",
    "    keypoints = [kp['xyz'] for kp in entry['keypoints']]\n",
    "    keypoints = np.array(keypoints, dtype=np.float32)\n",
    "    model_id_to_keypoints[model_id] = keypoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0609f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using minimal PointNet (not full PointNet++)\n",
    "class PointNetKeypointRegressor(nn.Module):\n",
    "    def __init__(self, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.sa1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_keypoints * 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, 3]\n",
    "        x = x.permute(0, 2, 1)  # [B, 3, N]\n",
    "        x = self.sa1(x)  # [B, 1024, N]\n",
    "        x = torch.max(x, 2)[0]  # [B, 1024]\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, NUM_KEYPOINTS, 3)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeNetKeypointDataset(Dataset):\n",
    "    def __init__(self, mesh_dir, annotation_json):\n",
    "        self.mesh_dir = mesh_dir\n",
    "        self.samples = []\n",
    "\n",
    "        #count_valid = 0\n",
    "        #count_total = 0\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotation_json) as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        for entry in annotations:\n",
    "            model_id = entry['model_id']\n",
    "            #print(model_id)\n",
    "            keypoints = np.array([kp['xyz'] for kp in entry['keypoints']], dtype=np.float32)\n",
    "            #count_total += 1\n",
    "            if keypoints.shape[0] != NUM_KEYPOINTS:\n",
    "                continue  # Strictly filter only 6-keypoint meshes\n",
    "            self.samples.append((model_id, keypoints))\n",
    "            #count_valid += 1\n",
    "\n",
    "        #print(f\"Total meshes: {count_total}, Valid 6-keypoint meshes: {count_valid}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_id, keypoints = self.samples[idx]\n",
    "\n",
    "        #print(\"Inside __getitem__: keypoints.shape =\", keypoints.shape) \n",
    "\n",
    "        mesh_path = os.path.join(self.mesh_dir, model_id + \".ply\")\n",
    "\n",
    "        try:\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "            if points.shape[0] < NUM_POINTS:\n",
    "                pad_size = NUM_POINTS - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {model_id}: {e}\")\n",
    "            points = np.zeros((NUM_POINTS, 3), dtype=np.float32)\n",
    "            keypoints = np.zeros((NUM_KEYPOINTS, 3), dtype=np.float32)\n",
    "\n",
    "        # Normalize\n",
    "        #print(\"Points Min:\", np.min(points), \"Max:\", np.max(points))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        points = (points - centroid) / scale\n",
    "        keypoints = (keypoints - centroid) / scale\n",
    "\n",
    "\n",
    "        return torch.from_numpy(points).float(), torch.from_numpy(keypoints).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff21819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca84ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 1024 # Minimum 512 for input, ~1000 for neighborhood density; 2^14 = 16384\n",
    "NUM_KEYPOINTS = 9 # 2 meshes have 5 keypoints idk why\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc4b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 2348\n",
      "Test dataset size: 587\n",
      "Pred range: [-0.562, 0.643]\n",
      "Target range: [-1.006, 1.010]\n",
      "Epoch 1/50\n",
      "Train Loss: 0.061864; Validation Loss: 0.078836\n",
      "Pred range: [-1.589, 1.309]\n",
      "Target range: [-1.019, 1.024]\n",
      "Epoch 2/50\n",
      "Train Loss: 0.009446; Validation Loss: 0.076760\n",
      "Pred range: [-1.165, 1.176]\n",
      "Target range: [-1.004, 1.019]\n",
      "Epoch 3/50\n",
      "Train Loss: 0.005098; Validation Loss: 0.078935\n",
      "Pred range: [-1.122, 1.128]\n",
      "Target range: [-1.008, 1.017]\n",
      "Epoch 4/50\n",
      "Train Loss: 0.004269; Validation Loss: 0.006506\n",
      "Pred range: [-1.094, 1.233]\n",
      "Target range: [-1.000, 1.026]\n",
      "Epoch 5/50\n",
      "Train Loss: 0.004929; Validation Loss: 0.003952\n",
      "Pred range: [-1.178, 1.042]\n",
      "Target range: [-1.002, 1.058]\n",
      "Epoch 6/50\n",
      "Train Loss: 0.003864; Validation Loss: 0.003656\n",
      "Pred range: [-0.999, 0.992]\n",
      "Target range: [-1.014, 1.022]\n",
      "Epoch 7/50\n",
      "Train Loss: 0.003378; Validation Loss: 0.003265\n",
      "Pred range: [-1.072, 1.074]\n",
      "Target range: [-1.008, 1.045]\n",
      "Epoch 8/50\n",
      "Train Loss: 0.003724; Validation Loss: 0.003114\n",
      "Pred range: [-1.088, 1.071]\n",
      "Target range: [-1.013, 1.026]\n",
      "Epoch 9/50\n",
      "Train Loss: 0.002975; Validation Loss: 0.002911\n",
      "Pred range: [-1.053, 1.068]\n",
      "Target range: [-1.022, 1.021]\n",
      "Epoch 10/50\n",
      "Train Loss: 0.002698; Validation Loss: 0.002819\n",
      "Pred range: [-1.038, 1.025]\n",
      "Target range: [-1.018, 1.032]\n",
      "Epoch 11/50\n",
      "Train Loss: 0.002806; Validation Loss: 0.002766\n",
      "Pred range: [-1.075, 1.186]\n",
      "Target range: [-1.019, 1.018]\n",
      "Epoch 12/50\n",
      "Train Loss: 0.002781; Validation Loss: 0.002678\n",
      "Pred range: [-1.039, 1.033]\n",
      "Target range: [-1.004, 1.031]\n",
      "Epoch 13/50\n",
      "Train Loss: 0.002526; Validation Loss: 0.002437\n",
      "Pred range: [-1.024, 1.039]\n",
      "Target range: [-1.025, 1.021]\n",
      "Epoch 14/50\n",
      "Train Loss: 0.002303; Validation Loss: 0.002407\n",
      "Pred range: [-1.026, 1.028]\n",
      "Target range: [-1.008, 1.017]\n",
      "Epoch 15/50\n",
      "Train Loss: 0.002410; Validation Loss: 0.002418\n",
      "Pred range: [-1.092, 1.073]\n",
      "Target range: [-1.013, 1.023]\n",
      "Epoch 16/50\n",
      "Train Loss: 0.002153; Validation Loss: 0.002246\n",
      "Pred range: [-1.116, 1.033]\n",
      "Target range: [-1.016, 1.020]\n",
      "Epoch 17/50\n",
      "Train Loss: 0.001964; Validation Loss: 0.002272\n",
      "Pred range: [-0.990, 1.086]\n",
      "Target range: [-1.022, 1.038]\n",
      "Epoch 18/50\n",
      "Train Loss: 0.001854; Validation Loss: 0.002143\n",
      "Pred range: [-1.033, 0.986]\n",
      "Target range: [-1.002, 1.022]\n",
      "Epoch 19/50\n",
      "Train Loss: 0.001919; Validation Loss: 0.002829\n",
      "Pred range: [-1.141, 1.018]\n",
      "Target range: [-1.000, 1.020]\n",
      "Epoch 20/50\n",
      "Train Loss: 0.001836; Validation Loss: 0.001893\n",
      "Pred range: [-1.007, 1.028]\n",
      "Target range: [-1.004, 1.010]\n",
      "Epoch 21/50\n",
      "Train Loss: 0.001693; Validation Loss: 0.002058\n",
      "Pred range: [-1.099, 1.047]\n",
      "Target range: [-1.002, 1.020]\n",
      "Epoch 22/50\n",
      "Train Loss: 0.001674; Validation Loss: 0.001857\n",
      "Pred range: [-1.136, 1.124]\n",
      "Target range: [-1.005, 1.023]\n",
      "Epoch 23/50\n",
      "Train Loss: 0.001685; Validation Loss: 0.001791\n",
      "Pred range: [-1.051, 1.009]\n",
      "Target range: [-1.016, 1.060]\n",
      "Epoch 24/50\n",
      "Train Loss: 0.001621; Validation Loss: 0.001819\n",
      "Pred range: [-1.094, 1.138]\n",
      "Target range: [-1.010, 1.023]\n",
      "Epoch 25/50\n",
      "Train Loss: 0.001770; Validation Loss: 0.001839\n",
      "Pred range: [-1.138, 1.078]\n",
      "Target range: [-1.008, 1.012]\n",
      "Epoch 26/50\n",
      "Train Loss: 0.001791; Validation Loss: 0.001787\n",
      "Pred range: [-0.999, 1.056]\n",
      "Target range: [-1.019, 1.013]\n",
      "Epoch 27/50\n",
      "Train Loss: 0.001661; Validation Loss: 0.001774\n",
      "Pred range: [-1.119, 1.036]\n",
      "Target range: [-1.001, 1.032]\n",
      "Epoch 28/50\n",
      "Train Loss: 0.001615; Validation Loss: 0.001776\n",
      "Pred range: [-1.008, 1.036]\n",
      "Target range: [-1.012, 1.016]\n",
      "Epoch 29/50\n",
      "Train Loss: 0.001461; Validation Loss: 0.001715\n",
      "Pred range: [-1.021, 1.090]\n",
      "Target range: [-1.012, 1.022]\n",
      "Epoch 30/50\n",
      "Train Loss: 0.001470; Validation Loss: 0.001538\n",
      "Pred range: [-1.047, 1.090]\n",
      "Target range: [-1.005, 1.017]\n",
      "Epoch 31/50\n",
      "Train Loss: 0.001395; Validation Loss: 0.001664\n",
      "Pred range: [-1.076, 1.011]\n",
      "Target range: [-1.013, 1.010]\n",
      "Epoch 32/50\n",
      "Train Loss: 0.001466; Validation Loss: 0.001562\n",
      "Pred range: [-1.068, 1.029]\n",
      "Target range: [-1.010, 1.021]\n",
      "Epoch 33/50\n",
      "Train Loss: 0.001473; Validation Loss: 0.001551\n",
      "Pred range: [-1.048, 1.053]\n",
      "Target range: [-1.014, 1.015]\n",
      "Epoch 34/50\n",
      "Train Loss: 0.001384; Validation Loss: 0.001462\n",
      "Pred range: [-1.091, 1.050]\n",
      "Target range: [-1.002, 1.014]\n",
      "Epoch 35/50\n",
      "Train Loss: 0.001225; Validation Loss: 0.001497\n",
      "Pred range: [-1.013, 1.031]\n",
      "Target range: [-1.010, 1.027]\n",
      "Epoch 36/50\n",
      "Train Loss: 0.001209; Validation Loss: 0.001517\n",
      "Pred range: [-1.083, 1.131]\n",
      "Target range: [-1.011, 1.027]\n",
      "Epoch 37/50\n",
      "Train Loss: 0.001290; Validation Loss: 0.001573\n",
      "Pred range: [-1.025, 1.072]\n",
      "Target range: [-1.015, 1.014]\n",
      "Epoch 38/50\n",
      "Train Loss: 0.001380; Validation Loss: 0.001592\n",
      "Pred range: [-1.092, 1.055]\n",
      "Target range: [-1.024, 1.015]\n",
      "Epoch 39/50\n",
      "Train Loss: 0.001383; Validation Loss: 0.001867\n",
      "Pred range: [-1.127, 0.955]\n",
      "Target range: [-1.033, 1.024]\n",
      "Epoch 40/50\n",
      "Train Loss: 0.001426; Validation Loss: 0.001694\n",
      "Pred range: [-0.971, 1.060]\n",
      "Target range: [-1.005, 1.011]\n",
      "Epoch 41/50\n",
      "Train Loss: 0.001285; Validation Loss: 0.001520\n",
      "Pred range: [-1.072, 0.991]\n",
      "Target range: [-1.003, 1.050]\n",
      "Epoch 42/50\n",
      "Train Loss: 0.001344; Validation Loss: 0.001655\n",
      "Pred range: [-0.992, 1.077]\n",
      "Target range: [-1.002, 1.022]\n",
      "Epoch 43/50\n",
      "Train Loss: 0.001341; Validation Loss: 0.001684\n",
      "Pred range: [-1.005, 1.017]\n",
      "Target range: [-1.001, 1.016]\n",
      "Epoch 44/50\n",
      "Train Loss: 0.001169; Validation Loss: 0.001585\n",
      "Pred range: [-1.093, 1.061]\n",
      "Target range: [-1.015, 1.026]\n",
      "Epoch 45/50\n",
      "Train Loss: 0.001126; Validation Loss: 0.001376\n",
      "Pred range: [-1.046, 1.072]\n",
      "Target range: [-1.018, 1.016]\n",
      "Epoch 46/50\n",
      "Train Loss: 0.001085; Validation Loss: 0.001497\n",
      "Pred range: [-1.030, 1.035]\n",
      "Target range: [-1.013, 1.010]\n",
      "Epoch 47/50\n",
      "Train Loss: 0.001149; Validation Loss: 0.001403\n",
      "Pred range: [-1.073, 1.015]\n",
      "Target range: [-0.996, 1.018]\n",
      "Epoch 48/50\n",
      "Train Loss: 0.001242; Validation Loss: 0.001517\n",
      "Pred range: [-1.104, 1.076]\n",
      "Target range: [-1.011, 1.016]\n",
      "Epoch 49/50\n",
      "Train Loss: 0.001293; Validation Loss: 0.001450\n",
      "Pred range: [-0.980, 1.054]\n",
      "Target range: [-1.013, 1.012]\n",
      "Epoch 50/50\n",
      "Train Loss: 0.001085; Validation Loss: 0.001489\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "dataset = ShapeNetKeypointDataset(mesh_dir=\"Guitars/9_Augmented\", annotation_json=\"guitar_9_augmented.json\")  \n",
    "\n",
    "total_size = len(dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(val_dataset)}\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "\n",
    "#model = PointNetKeypointRegressor(NUM_KEYPOINTS).to(device)\n",
    "model = get_model(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "if False: # For resuming.\n",
    "    os.makedirs(\"train_checkpoints\", exist_ok=True)\n",
    "\n",
    "    #resume_checkpoint_path = \"saved_models/guitarnet_final.pth\"\n",
    "    resume_checkpoint_path = \"train_checkpoints/guitarnet++_epoch_50.pth\"\n",
    "    if os.path.exists(resume_checkpoint_path):\n",
    "        checkpoint = torch.load(resume_checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        val_losses = checkpoint.get('val_losses', [])\n",
    "\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "total_epoch = 50 # Additional epochs to train \n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    #num_batches = 0\n",
    "    \n",
    "    for batch_idx, (pts, kps) in enumerate(train_loader):\n",
    "        try:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0, 2, 1) #Permute to fit input size\n",
    "            \n",
    "            # Forward pass\n",
    "            preds, _ = model(pts)\n",
    "            loss = F.mse_loss(preds, kps)\n",
    "            #loss = nn.MSELoss() # Not sure why this one is better tbh\n",
    "            \n",
    "            # Back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_train_loss += loss.item()\n",
    "            #num_batches += 1\n",
    "            \n",
    "            #if epoch == 0 and batch_idx == 0:\n",
    "            if batch_idx == 0:\n",
    "                #print(f\"First batch - Input shape: {pts.shape}, Target shape: {kps.shape}\")\n",
    "                #print(f\"First batch loss: {loss.item():.6f}\")\n",
    "                print(f\"Pred range: [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "                print(f\"Target range: [{kps.min():.3f}, {kps.max():.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Average train loss\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for pts, kps in val_loader:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0,2,1)\n",
    "            preds, _ = model(pts)\n",
    "            val_loss = F.mse_loss(preds, kps)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss/len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    if True:\n",
    "        if epoch + start_epoch + 1 % 5 == 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.8\n",
    "                print(\"Force-reduced LR to 80%\")\n",
    "\n",
    "    if False:\n",
    "        if epoch + start_epoch + 1 == 20:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 1e-4\n",
    "            print(\"Reduced LR to 1e-4\")\n",
    "    if False: #For checkpointing\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint_path = f\"train_checkpoints/guitarnet++_lin_3_epoch_{start_epoch + epoch+1}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': start_epoch + epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+ start_epoch + 1}/{start_epoch + total_epoch}\\nTrain Loss: {avg_train_loss:.6f}; Validation Loss: {avg_val_loss:.6f}\")\n",
    "if False: #For save when done\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        'loss': avg_train_loss,\n",
    "        'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "    }, \"saved_models/guitarnet++_lin_3_final.pth\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7d909c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:31\u001b[0m, in \u001b[0;36mget_model.__init__\u001b[0;34m(self, num_class, normal_channel)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#self.drop2 = nn.Dropout(0.5) #Same here >> 0.3\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.3\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m256\u001b[39m, \u001b[43mnum_keypoints\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Train dataset size: 2348\n",
    "Test dataset size: 587\n",
    "First batch - Input shape: torch.Size([256, 3, 1024]), Target shape: torch.Size([256, 9, 3])\n",
    "First batch loss: 0.288146\n",
    "Pred range: [-1.969, 1.959]\n",
    "Target range: [-1.001, 1.021]\n",
    "Epoch 1/50\n",
    "Train Loss: 0.150820; Validation Loss: 0.103047\n",
    "Epoch 2/50\n",
    "Train Loss: 0.066115; Validation Loss: 0.124546\n",
    "Epoch 3/50\n",
    "Train Loss: 0.043645; Validation Loss: 0.078913\n",
    "Epoch 4/50\n",
    "Train Loss: 0.030031; Validation Loss: 0.087326\n",
    "Epoch 5/50\n",
    "Train Loss: 0.022437; Validation Loss: 0.085578\n",
    "Epoch 6/50\n",
    "Train Loss: 0.019087; Validation Loss: 0.046889\n",
    "Epoch 7/50\n",
    "Train Loss: 0.015242; Validation Loss: 0.013829\n",
    "Epoch 8/50\n",
    "Train Loss: 0.012592; Validation Loss: 0.006803\n",
    "Epoch 9/50\n",
    "Train Loss: 0.011893; Validation Loss: 0.005015\n",
    "Epoch 10/50\n",
    "Train Loss: 0.011156; Validation Loss: 0.009370\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6421fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45cf500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': [avg_train_loss, avg_val_loss],\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet++_lin_4_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6e70b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_keypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_KEYPOINTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:62\u001b[0m, in \u001b[0;36mget_model_msg.__init__\u001b[0;34m(self, num_keypoints, normal_channel)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_keypoints, normal_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     63\u001b[0m     in_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normal_channel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_keypoints \u001b[38;5;241m=\u001b[39m num_keypoints\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = get_model_msg(num_keypoints=NUM_KEYPOINTS, normal_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7c61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path):\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create model with same architecture\n",
    "    model = get_model_msg(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    #model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    #print(f\"Model loaded! Trained for {checkpoint['epoch']+1} epochs, final loss: {checkpoint['loss'][0]:.6f}, {checkpoint['loss'][1]:.6f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5869abb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/guitarnet++_final.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mload_saved_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create model with same architecture\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_keypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_KEYPOINTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[1;32m      9\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:62\u001b[0m, in \u001b[0;36mget_model_msg.__init__\u001b[0;34m(self, num_keypoints, normal_channel)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_keypoints, normal_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     63\u001b[0m     in_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normal_channel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_keypoints \u001b[38;5;241m=\u001b[39m num_keypoints\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "474c6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    \"\"\"Predict keypoints for a single cap .ply file\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    try:\n",
    "        # Load and process mesh (same as your training preprocessing)\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "        \n",
    "        # Sample points\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "        \n",
    "        # Normalize (exactly like training)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        \n",
    "        # Denormalize keypoints back to original scale\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "        \n",
    "        return original_keypoints, normalized_keypoints\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b7a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "   \n",
    "    mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "    if mesh.is_empty or len(mesh.faces) == 0:\n",
    "        raise ValueError(\"Empty mesh\")\n",
    "\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "    if points.shape[0] < NUM_POINTS:\n",
    "        pad_size = NUM_POINTS - points.shape[0]\n",
    "        pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "        points = np.vstack((points, pad))\n",
    "\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "    normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "\n",
    "    points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "    points_tensor = points_tensor.permute(0, 2, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        output = model(points_tensor)\n",
    "        normalized_keypoints = output[0].cpu().numpy().squeeze(0)\n",
    "        \n",
    "\n",
    "    original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "\n",
    "    return original_keypoints, normalized_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "592d83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints_no_normalization(model, ply_file_path):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    try:\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "\n",
    "        points_tensor = torch.from_numpy(points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_keypoints = model(points_tensor)[0].cpu().numpy().squeeze(0)\n",
    "\n",
    "        return predicted_keypoints, predicted_keypoints  # same, no normalization\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f391077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(model, ply_folder):\n",
    "    \"\"\"Predict keypoints for all .ply files in a folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    ply_files = [os.path.join(ply_folder, f) for f in os.listdir(ply_folder) if f.endswith('.ply')]\n",
    "    print(f\"Found {len(ply_files)} .ply files\")\n",
    "    \n",
    "    for ply_file in ply_files:\n",
    "        print(f\"Processing {os.path.basename(ply_file)}...\")\n",
    "        keypoints, normalized_kp = predict_keypoints(model, ply_file)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            results[os.path.basename(ply_file)] = {\n",
    "                'original_keypoints': keypoints,\n",
    "                'normalized_keypoints': normalized_kp\n",
    "            }\n",
    "            print(f\"  Success! Predicted {len(keypoints)} keypoints\")\n",
    "        else:\n",
    "            print(f\"  Failed to process {ply_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49173634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'tuple' object has no attribute 'cpu'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_keypoints_no_normalization(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a18aace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_2_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5a96318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.024 -0.234 0.012\n",
      "0.020 -0.227 0.003\n",
      "0.037 -0.202 0.002\n",
      "0.035 -0.208 0.046\n",
      "-0.018 -0.232 0.033\n",
      "0.015 -0.222 0.023\n",
      "-0.017 -0.235 -0.006\n",
      "-0.015 -0.241 0.039\n",
      "0.041 -0.233 -0.015\n"
     ]
    }
   ],
   "source": [
    "keypoints, norm_kp = predict_keypoints(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")\n",
    "if keypoints is not None:\n",
    "    #print(\"Predicted keypoints:\")\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        print(f\"{kp[0]:.3f} {kp[1]:.3f} {kp[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26eb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf273e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd10b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8826310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 2048  # or match what you used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3d6fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Load a .ply mesh, sample and normalize points, and predict keypoints using the trained model.\n",
    "    Returns: (N, 3) keypoint array in mesh coordinates\n",
    "    \"\"\"\n",
    "    # Load and check mesh\n",
    "    mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "    if mesh.is_empty or len(mesh.faces) == 0:\n",
    "        raise ValueError(\"Empty or invalid mesh.\")\n",
    "\n",
    "    # Sample surface points\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "    if points.shape[0] < NUM_POINTS:\n",
    "        pad_size = NUM_POINTS - points.shape[0]\n",
    "        pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "        points = np.vstack((points, pad))\n",
    "\n",
    "    # Normalize (same as training)\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "    normalized_points = (points - centroid) / scale\n",
    "\n",
    "    # Convert to model input\n",
    "    points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0)  # shape (1, N, 3)\n",
    "    points_tensor = points_tensor.permute(0, 2, 1).to(device)  # (B, 3, N)\n",
    "\n",
    "    # Predict\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        keypoints_normalized, _ = model(points_tensor)  # (1, K, 3)\n",
    "\n",
    "    keypoints_normalized = keypoints_normalized.squeeze(0).cpu().numpy()\n",
    "    keypoints = keypoints_normalized * scale + centroid  # restore original coordinates\n",
    "\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df572e49",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/guitarnet++_lin_4_final.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mload_saved_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create model with same architecture\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_keypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_KEYPOINTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormal_channel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[1;32m      9\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/MLP-Mesh-Keypoint-Inference/pointnet2_keypoint_regressor.py:62\u001b[0m, in \u001b[0;36mget_model_msg.__init__\u001b[0;34m(self, num_keypoints, normal_channel)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_keypoints, normal_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     63\u001b[0m     in_channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normal_channel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_keypoints \u001b[38;5;241m=\u001b[39m num_keypoints\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_lin_4_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132eefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_keypoints()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
