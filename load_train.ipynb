{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc010216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from datetime import datetime \n",
    "\n",
    "from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
    "from pointnet2_keypoint_regressor import get_model\n",
    "\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b84a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "24fb5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guitar.json\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "model_id_to_keypoints = {}\n",
    "for entry in annotations:\n",
    "    model_id = entry['model_id']\n",
    "    keypoints = [kp['xyz'] for kp in entry['keypoints']]\n",
    "    keypoints = np.array(keypoints, dtype=np.float32)\n",
    "    model_id_to_keypoints[model_id] = keypoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0609f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using minimal PointNet (not full PointNet++)\n",
    "class PointNetKeypointRegressor(nn.Module):\n",
    "    def __init__(self, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.sa1 = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_keypoints * 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, 3]\n",
    "        x = x.permute(0, 2, 1)  # [B, 3, N]\n",
    "        x = self.sa1(x)  # [B, 1024, N]\n",
    "        x = torch.max(x, 2)[0]  # [B, 1024]\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, NUM_KEYPOINTS, 3)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeNetKeypointDataset(Dataset):\n",
    "    def __init__(self, mesh_dir, annotation_json):\n",
    "        self.mesh_dir = mesh_dir\n",
    "        self.samples = []\n",
    "\n",
    "        #count_valid = 0\n",
    "        #count_total = 0\n",
    "\n",
    "        # Load annotations\n",
    "        with open(annotation_json) as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        for entry in annotations:\n",
    "            model_id = entry['model_id']\n",
    "            #print(model_id)\n",
    "            keypoints = np.array([kp['xyz'] for kp in entry['keypoints']], dtype=np.float32)\n",
    "            #count_total += 1\n",
    "            if keypoints.shape[0] != NUM_KEYPOINTS:\n",
    "                continue  # Strictly filter only 6-keypoint meshes\n",
    "            self.samples.append((model_id, keypoints))\n",
    "            #count_valid += 1\n",
    "\n",
    "        #print(f\"Total meshes: {count_total}, Valid 6-keypoint meshes: {count_valid}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        model_id, keypoints = self.samples[idx]\n",
    "\n",
    "        #print(\"Inside __getitem__: keypoints.shape =\", keypoints.shape) \n",
    "\n",
    "        mesh_path = os.path.join(self.mesh_dir, model_id + \".ply\")\n",
    "\n",
    "        try:\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "            if points.shape[0] < NUM_POINTS:\n",
    "                pad_size = NUM_POINTS - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {model_id}: {e}\")\n",
    "            points = np.zeros((NUM_POINTS, 3), dtype=np.float32)\n",
    "            keypoints = np.zeros((NUM_KEYPOINTS, 3), dtype=np.float32)\n",
    "\n",
    "        # Normalize\n",
    "        #print(\"Points Min:\", np.min(points), \"Max:\", np.max(points))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        points = (points - centroid) / scale\n",
    "        keypoints = (keypoints - centroid) / scale\n",
    "\n",
    "\n",
    "        return torch.from_numpy(points).float(), torch.from_numpy(keypoints).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca84ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 8192 #Maybe do 512\n",
    "NUM_KEYPOINTS = 9 # 2 meshes have 5 keypoints idk why\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efc4b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 469\n",
      "First batch - Input shape: torch.Size([32, 3, 8192]), Target shape: torch.Size([32, 9, 3])\n",
      "First batch loss: 0.402841\n",
      "Pred range: [-1.905, 1.477]\n",
      "Target range: [-0.749, 1.001]\n",
      "Epoch 1/50\n",
      "Train Loss: 0.283798; Validation Loss: 0.035835\n",
      "Epoch 2/50\n",
      "Train Loss: 0.172636; Validation Loss: 0.042654\n",
      "Epoch 3/50\n",
      "Train Loss: 0.121219; Validation Loss: 0.051110\n",
      "Epoch 4/50\n",
      "Train Loss: 0.093375; Validation Loss: 0.024118\n",
      "Epoch 5/50\n",
      "Train Loss: 0.077583; Validation Loss: 0.013700\n",
      "Epoch 6/50\n",
      "Train Loss: 0.061444; Validation Loss: 0.010143\n",
      "Epoch 7/50\n",
      "Train Loss: 0.048456; Validation Loss: 0.008139\n",
      "Epoch 8/50\n",
      "Train Loss: 0.048267; Validation Loss: 0.012978\n",
      "Epoch 9/50\n",
      "Train Loss: 0.036501; Validation Loss: 0.008710\n",
      "Saved checkpoint: train_checkpoints/guitarnet++_epoch_10.pth\n",
      "Epoch 10/50\n",
      "Train Loss: 0.030453; Validation Loss: 0.005229\n",
      "Epoch 11/50\n",
      "Train Loss: 0.022284; Validation Loss: 0.005536\n",
      "Epoch 12/50\n",
      "Train Loss: 0.020704; Validation Loss: 0.004808\n",
      "Epoch 13/50\n",
      "Train Loss: 0.018637; Validation Loss: 0.004555\n",
      "Epoch 14/50\n",
      "Train Loss: 0.015929; Validation Loss: 0.003946\n",
      "Epoch 15/50\n",
      "Train Loss: 0.015383; Validation Loss: 0.004318\n",
      "Epoch 16/50\n",
      "Train Loss: 0.013085; Validation Loss: 0.004039\n",
      "Epoch 17/50\n",
      "Train Loss: 0.012324; Validation Loss: 0.003234\n",
      "Epoch 18/50\n",
      "Train Loss: 0.011838; Validation Loss: 0.004120\n",
      "Epoch 19/50\n",
      "Train Loss: 0.011992; Validation Loss: 0.003177\n",
      "Saved checkpoint: train_checkpoints/guitarnet++_epoch_20.pth\n",
      "Epoch 20/50\n",
      "Train Loss: 0.010630; Validation Loss: 0.004979\n",
      "Epoch 21/50\n",
      "Train Loss: 0.010746; Validation Loss: 0.002922\n",
      "Epoch 22/50\n",
      "Train Loss: 0.009801; Validation Loss: 0.003547\n",
      "Epoch 23/50\n",
      "Train Loss: 0.009374; Validation Loss: 0.003415\n",
      "Epoch 24/50\n",
      "Train Loss: 0.008487; Validation Loss: 0.004059\n",
      "Epoch 25/50\n",
      "Train Loss: 0.008570; Validation Loss: 0.002887\n",
      "Epoch 26/50\n",
      "Train Loss: 0.007764; Validation Loss: 0.002491\n",
      "Epoch 27/50\n",
      "Train Loss: 0.007128; Validation Loss: 0.003994\n",
      "Epoch 28/50\n",
      "Train Loss: 0.007946; Validation Loss: 0.003791\n",
      "Epoch 29/50\n",
      "Train Loss: 0.008858; Validation Loss: 0.002608\n",
      "Saved checkpoint: train_checkpoints/guitarnet++_epoch_30.pth\n",
      "Epoch 30/50\n",
      "Train Loss: 0.006855; Validation Loss: 0.003336\n",
      "Epoch 31/50\n",
      "Train Loss: 0.006986; Validation Loss: 0.002729\n",
      "Epoch 32/50\n",
      "Train Loss: 0.006798; Validation Loss: 0.002767\n",
      "Epoch 33/50\n",
      "Train Loss: 0.006090; Validation Loss: 0.002923\n",
      "Epoch 34/50\n",
      "Train Loss: 0.006302; Validation Loss: 0.002441\n",
      "Epoch 35/50\n",
      "Train Loss: 0.005769; Validation Loss: 0.003165\n",
      "Epoch 36/50\n",
      "Train Loss: 0.005822; Validation Loss: 0.002414\n",
      "Epoch 37/50\n",
      "Train Loss: 0.005634; Validation Loss: 0.003408\n",
      "Epoch 38/50\n",
      "Train Loss: 0.005393; Validation Loss: 0.003029\n",
      "Epoch 39/50\n",
      "Train Loss: 0.004681; Validation Loss: 0.002925\n",
      "Saved checkpoint: train_checkpoints/guitarnet++_epoch_40.pth\n",
      "Epoch 40/50\n",
      "Train Loss: 0.004979; Validation Loss: 0.002535\n",
      "Epoch 41/50\n",
      "Train Loss: 0.004755; Validation Loss: 0.002833\n",
      "Epoch 42/50\n",
      "Train Loss: 0.006340; Validation Loss: 0.002785\n",
      "Epoch 43/50\n",
      "Train Loss: 0.005614; Validation Loss: 0.002664\n",
      "Epoch 44/50\n",
      "Train Loss: 0.005292; Validation Loss: 0.002895\n",
      "Epoch 45/50\n",
      "Train Loss: 0.004442; Validation Loss: 0.003023\n",
      "Epoch 46/50\n",
      "Train Loss: 0.004719; Validation Loss: 0.002410\n",
      "Epoch 47/50\n",
      "Train Loss: 0.004885; Validation Loss: 0.002754\n",
      "Epoch 48/50\n",
      "Train Loss: 0.004426; Validation Loss: 0.002063\n",
      "Epoch 49/50\n",
      "Train Loss: 0.004380; Validation Loss: 0.003511\n",
      "Saved checkpoint: train_checkpoints/guitarnet++_epoch_50.pth\n",
      "Epoch 50/50\n",
      "Train Loss: 0.004393; Validation Loss: 0.002419\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "dataset = ShapeNetKeypointDataset(mesh_dir=\"Guitars/9_points/\", annotation_json=\"guitar_train.json\")  \n",
    "\n",
    "total_size = len(dataset)\n",
    "val_size = int(0.2 * total_size)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "#dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "#model = PointNetKeypointRegressor(NUM_KEYPOINTS).to(device)\n",
    "model = get_model(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "if False: # For resuming.\n",
    "    os.makedirs(\"train_checkpoints\", exist_ok=True)\n",
    "\n",
    "    #resume_checkpoint_path = \"saved_models/guitarnet_final.pth\"\n",
    "    resume_checkpoint_path = \"train_checkpoints/guitarnet_epoch_45.pth\"\n",
    "    if os.path.exists(resume_checkpoint_path):\n",
    "        checkpoint = torch.load(resume_checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "total_epoch = 50 # Additional epochs to train \n",
    "for epoch in range(total_epoch):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    #num_batches = 0\n",
    "    \n",
    "    for batch_idx, (pts, kps) in enumerate(train_loader):\n",
    "        try:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0, 2, 1) #Permute to fit input size\n",
    "            \n",
    "            # Forward pass\n",
    "            preds = model(pts)\n",
    "            loss = F.mse_loss(preds, kps)\n",
    "            #loss = nn.MSELoss() # Not sure why this one is better tbh\n",
    "            \n",
    "            # Back pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_train_loss += loss.item()\n",
    "            #num_batches += 1\n",
    "            \n",
    "            if epoch == 0 and batch_idx == 0:\n",
    "                print(f\"First batch - Input shape: {pts.shape}, Target shape: {kps.shape}\")\n",
    "                print(f\"First batch loss: {loss.item():.6f}\")\n",
    "                print(f\"Pred range: [{preds.min():.3f}, {preds.max():.3f}]\")\n",
    "                print(f\"Target range: [{kps.min():.3f}, {kps.max():.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Average train loss\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for pts, kps in val_loader:\n",
    "            pts, kps = pts.to(device), kps.to(device)\n",
    "            pts = pts.permute(0,2,1)\n",
    "            preds = model(pts)\n",
    "            val_loss = F.mse_loss(preds, kps)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss/len(val_loader)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = f\"train_checkpoints/guitarnet++_epoch_{start_epoch + epoch+1}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': start_epoch + epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_train_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+ start_epoch + 1}/{start_epoch + total_epoch}\\nTrain Loss: {avg_train_loss:.6f}; Validation Loss: {avg_val_loss:.6f}\")\n",
    "    \n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': avg_train_loss,\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet++_final.pth\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6421fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45cf500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'loss': avg_loss,\n",
    "    'config': {'num_keypoints': NUM_KEYPOINTS, 'num_points': NUM_POINTS}\n",
    "}, \"saved_models/guitarnet++_epoch_12.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e70b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d7c61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_path):\n",
    "    \"\"\"Load your saved model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Create model with same architecture\n",
    "    model = get_model(num_keypoints=NUM_KEYPOINTS, normal_channel=False).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded! Trained for {checkpoint['epoch']+1} epochs, final loss: {checkpoint['loss']:.6f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c6f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    \"\"\"Predict keypoints for a single cap .ply file\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    try:\n",
    "        # Load and process mesh (same as your training preprocessing)\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "        \n",
    "        # Sample points\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "        \n",
    "        # Normalize (exactly like training)\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "        \n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "        \n",
    "        # Denormalize keypoints back to original scale\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "        \n",
    "        return original_keypoints, normalized_keypoints\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b7a48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keypoints(model, ply_file_path):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    try:\n",
    "        mesh = trimesh.load(ply_file_path, force='mesh')\n",
    "        if mesh.is_empty or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Empty mesh\")\n",
    "\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, NUM_POINTS)\n",
    "        if points.shape[0] < NUM_POINTS:\n",
    "            pad_size = NUM_POINTS - points.shape[0]\n",
    "            pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "            points = np.vstack((points, pad))\n",
    "\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        normalized_points = (points - centroid) / scale if scale > 0 else points - centroid\n",
    "\n",
    "        points_tensor = torch.from_numpy(normalized_points).float().unsqueeze(0).to(device)\n",
    "        points_tensor = points_tensor.permute(0, 2, 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            normalized_keypoints = model(points_tensor).cpu().numpy().squeeze(0)\n",
    "\n",
    "        original_keypoints = normalized_keypoints * scale + centroid if scale > 0 else normalized_keypoints + centroid\n",
    "\n",
    "        return original_keypoints, normalized_keypoints\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ply_file_path}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f391077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(model, ply_folder):\n",
    "    \"\"\"Predict keypoints for all .ply files in a folder\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    ply_files = [os.path.join(ply_folder, f) for f in os.listdir(ply_folder) if f.endswith('.ply')]\n",
    "    print(f\"Found {len(ply_files)} .ply files\")\n",
    "    \n",
    "    for ply_file in ply_files:\n",
    "        print(f\"Processing {os.path.basename(ply_file)}...\")\n",
    "        keypoints, normalized_kp = predict_cap_keypoints(model, ply_file)\n",
    "        \n",
    "        if keypoints is not None:\n",
    "            results[os.path.basename(ply_file)] = {\n",
    "                'original_keypoints': keypoints,\n",
    "                'normalized_keypoints': normalized_kp\n",
    "            }\n",
    "            print(f\"  Success! Predicted {len(keypoints)} keypoints\")\n",
    "        else:\n",
    "            print(f\"  Failed to process {ply_file}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a18aace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! Trained for 50 epochs, final loss: 0.004393\n"
     ]
    }
   ],
   "source": [
    "model = load_saved_model(\"saved_models/guitarnet++_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5a96318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010 0.354 0.010\n",
      "0.012 -0.211 -0.001\n",
      "0.107 -0.164 0.013\n",
      "-0.086 -0.198 0.010\n",
      "0.125 -0.490 0.009\n",
      "-0.095 -0.488 0.019\n",
      "0.010 -0.514 0.009\n",
      "0.099 -0.321 0.012\n",
      "-0.078 -0.331 0.007\n"
     ]
    }
   ],
   "source": [
    "keypoints, norm_kp = predict_keypoints(model, \"Guitars/9_points/ef1c22bd3b74953689f0379846507dd3.ply\")\n",
    "if keypoints is not None:\n",
    "    #print(\"Predicted keypoints:\")\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        print(f\"{kp[0]:.3f} {kp[1]:.3f} {kp[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40413345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
