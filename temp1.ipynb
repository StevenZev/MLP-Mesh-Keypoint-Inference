{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72580a71",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4de7001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from datetime import datetime \n",
    "\n",
    "from pointnet2_utils import PointNetSetAbstractionMsg, PointNetSetAbstraction\n",
    "from pointnet2_keypoint_regressor import get_model#, get_model_msg\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6037d72",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for get_model:\n\tsize mismatch for sa1.mlp_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n\tsize mismatch for sa1.mlp_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_convs.2.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n\tsize mismatch for sa1.mlp_convs.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_convs.0.weight: copying a param with shape torch.Size([128, 131, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 259, 1, 1]).\n\tsize mismatch for sa2.mlp_convs.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_convs.1.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for sa2.mlp_convs.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_convs.2.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for sa2.mlp_convs.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.0.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.0.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.0.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_convs.0.weight: copying a param with shape torch.Size([256, 259, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1027, 1, 1]).\n\tsize mismatch for sa3.mlp_convs.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_convs.1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for sa3.mlp_convs.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_convs.2.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for sa3.mlp_convs.2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.0.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.0.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.0.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 266\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmesh_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 266\u001b[0m \u001b[43mpredict_points\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/kneenet++_4_5_final_2.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscans_2/12252.stl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 242\u001b[0m, in \u001b[0;36mpredict_points\u001b[0;34m(model_path, input_ply, save)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_points\u001b[39m(model_path, input_ply, save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 242\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[43mKeypointPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     mesh_path \u001b[38;5;241m=\u001b[39m input_ply \n\u001b[1;32m    245\u001b[0m     keypoints, points, metadata \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict_keypoints(mesh_path)\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mKeypointPredictor.__init__\u001b[0;34m(self, model_path, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m get_model(\n\u001b[1;32m     27\u001b[0m     num_keypoints\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_keypoints\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     28\u001b[0m     normal_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     29\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Load trained weights\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_keypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m keypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/pointnet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:2593\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2587\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2589\u001b[0m             ),\n\u001b[1;32m   2590\u001b[0m         )\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2594\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2596\u001b[0m         )\n\u001b[1;32m   2597\u001b[0m     )\n\u001b[1;32m   2598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for get_model:\n\tsize mismatch for sa1.mlp_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 1, 1]).\n\tsize mismatch for sa1.mlp_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_convs.2.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n\tsize mismatch for sa1.mlp_convs.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for sa1.mlp_bns.2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa1.mlp_bns.2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_convs.0.weight: copying a param with shape torch.Size([128, 131, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 259, 1, 1]).\n\tsize mismatch for sa2.mlp_convs.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_convs.1.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for sa2.mlp_convs.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_convs.2.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for sa2.mlp_convs.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.0.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.0.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.0.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for sa2.mlp_bns.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa2.mlp_bns.2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa2.mlp_bns.2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_convs.0.weight: copying a param with shape torch.Size([256, 259, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1027, 1, 1]).\n\tsize mismatch for sa3.mlp_convs.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_convs.1.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for sa3.mlp_convs.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_convs.2.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for sa3.mlp_convs.2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.0.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.0.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.0.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for sa3.mlp_bns.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for sa3.mlp_bns.2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for sa3.mlp_bns.2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 1024]) from checkpoint, the shape in current model is torch.Size([512, 2048])."
     ]
    }
   ],
   "source": [
    "class KeypointPredictor:\n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize the keypoint predictor\n",
    "        \n",
    "        Args:\n",
    "            model_path: path to saved model (.pth file)\n",
    "            device: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "\n",
    "        random.seed(0)\n",
    "        np.random.seed(0)\n",
    "        torch.manual_seed(0)\n",
    "        torch.cuda.manual_seed(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load model checkpoint\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        self.config = checkpoint.get('config', {'num_keypoints': 9, 'num_points': 1024})\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = get_model(\n",
    "            num_keypoints=self.config['num_keypoints'], \n",
    "            normal_channel=False\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load trained weights\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"Loaded model with {self.config['num_keypoints']} keypoints\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def load_and_sample_mesh(self, mesh_path, num_points=None):\n",
    "        \"\"\"\n",
    "        Load mesh and sample points from surface\n",
    "        \n",
    "        Args:\n",
    "            mesh_path: path to mesh file (.ply, .obj, etc.)\n",
    "            num_points: number of points to sample (default: from config)\n",
    "        \n",
    "        Returns:\n",
    "            points: numpy array of shape (num_points, 3)\n",
    "        \"\"\"\n",
    "        if num_points is None:\n",
    "            num_points = self.config['num_points']\n",
    "        \n",
    "        try:\n",
    "            # Load mesh\n",
    "            mesh = trimesh.load(mesh_path, force='mesh')\n",
    "            if mesh.is_empty or len(mesh.faces) == 0:\n",
    "                raise ValueError(\"Empty mesh\")\n",
    "            \n",
    "            # Sample points from surface\n",
    "            points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "            \n",
    "            # Handle case where mesh has fewer faces than requested points\n",
    "            if points.shape[0] < num_points:\n",
    "                pad_size = num_points - points.shape[0]\n",
    "                pad = np.repeat(points[0:1, :], pad_size, axis=0)\n",
    "                points = np.vstack((points, pad))\n",
    "            \n",
    "            return points.astype(np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mesh {mesh_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def normalize_points(self, points):\n",
    "        \"\"\"\n",
    "        Normalize points using same method as training\n",
    "        \n",
    "        Args:\n",
    "            points: numpy array of shape (num_points, 3)\n",
    "        \n",
    "        Returns:\n",
    "            normalized_points: numpy array of shape (num_points, 3)\n",
    "            centroid: numpy array of shape (3,) - for denormalization\n",
    "            scale: float - for denormalization\n",
    "        \"\"\"\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        scale = np.max(np.linalg.norm(points - centroid, axis=1))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if scale == 0:\n",
    "            scale = 1.0\n",
    "        \n",
    "        normalized_points = (points - centroid) / scale\n",
    "        return normalized_points, centroid, scale\n",
    "    \n",
    "    def denormalize_keypoints(self, keypoints, centroid, scale):\n",
    "        \"\"\"\n",
    "        Convert normalized keypoints back to original coordinate system\n",
    "        \n",
    "        Args:\n",
    "            keypoints: numpy array of shape (num_keypoints, 3)\n",
    "            centroid: numpy array of shape (3,)\n",
    "            scale: float\n",
    "        \n",
    "        Returns:\n",
    "            denormalized_keypoints: numpy array of shape (num_keypoints, 3)\n",
    "        \"\"\"\n",
    "        return keypoints * scale + centroid\n",
    "    \n",
    "    def predict_keypoints(self, mesh_path, return_normalized=False):\n",
    "        \"\"\"\n",
    "        Predict keypoints for a single mesh\n",
    "        \n",
    "        Args:\n",
    "            mesh_path: path to mesh file\n",
    "            return_normalized: if True, return keypoints in normalized coordinates\n",
    "        \n",
    "        Returns:\n",
    "            keypoints: numpy array of shape (num_keypoints, 3)\n",
    "            points: numpy array of shape (num_points, 3) - sampled points\n",
    "            metadata: dict with normalization info\n",
    "        \"\"\"\n",
    "        # Load and sample mesh\n",
    "        points = self.load_and_sample_mesh(mesh_path)\n",
    "        if points is None:\n",
    "            return None, None, None\n",
    "        \n",
    "        # Normalize points\n",
    "        normalized_points, centroid, scale = self.normalize_points(points)\n",
    "        \n",
    "        # Convert to tensor and add batch dimension\n",
    "        points_tensor = torch.from_numpy(normalized_points).float()\n",
    "        points_tensor = points_tensor.unsqueeze(0).permute(0, 2, 1).to(self.device)  # Shape: (1, 3, num_points)\n",
    "        \n",
    "        # Predict keypoints\n",
    "        with torch.no_grad():\n",
    "            predicted_keypoints, _ = self.model(points_tensor)\n",
    "        \n",
    "        # Convert back to numpy\n",
    "        predicted_keypoints = predicted_keypoints.squeeze(0).cpu().numpy()  # Shape: (num_keypoints, 3)\n",
    "        \n",
    "        # Denormalize if requested\n",
    "        if not return_normalized:\n",
    "            predicted_keypoints = self.denormalize_keypoints(predicted_keypoints, centroid, scale)\n",
    "            points_for_vis = points  # Original points\n",
    "        else:\n",
    "            points_for_vis = normalized_points\n",
    "        \n",
    "        metadata = {\n",
    "            'centroid': centroid,\n",
    "            'scale': scale,\n",
    "            'mesh_path': mesh_path\n",
    "        }\n",
    "        \n",
    "        return predicted_keypoints, points_for_vis, metadata\n",
    "    \n",
    "    def predict_batch(self, mesh_paths, return_normalized=False):\n",
    "        \"\"\"\n",
    "        Predict keypoints for multiple meshes\n",
    "        \n",
    "        Args:\n",
    "            mesh_paths: list of paths to mesh files\n",
    "            return_normalized: if True, return keypoints in normalized coordinates\n",
    "        \n",
    "        Returns:\n",
    "            results: list of (keypoints, points, metadata) tuples\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for mesh_path in mesh_paths:\n",
    "            result = self.predict_keypoints(mesh_path, return_normalized)\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "\n",
    "\n",
    "def save_keypoints_to_file(keypoints, output_path, mesh_path=None):\n",
    "    \"\"\"\n",
    "    Save keypoints to a text file\n",
    "    \n",
    "    Args:\n",
    "        keypoints: numpy array of shape (num_keypoints, 3)\n",
    "        output_path: path to save keypoints\n",
    "        mesh_path: original mesh path (for reference)\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        if mesh_path:\n",
    "            f.write(f\"# Keypoints for mesh: {mesh_path}\\n\")\n",
    "        f.write(f\"# Format: x y z\\n\")\n",
    "        f.write(f\"# Number of keypoints: {len(keypoints)}\\n\")\n",
    "        \n",
    "        for i, kp in enumerate(keypoints):\n",
    "            f.write(f\"{kp[0]:.6f} {kp[1]:.6f} {kp[2]:.6f}\\n\")\n",
    "    \n",
    "    print(f\"Keypoints saved to: {output_path}\")\n",
    "def visualize_keypoints_3d(points, keypoints, title=\"Predicted Keypoints\", figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Visualize point cloud with predicted keypoints\n",
    "    \n",
    "    Args:\n",
    "        points: numpy array of shape (num_points, 3)\n",
    "        keypoints: numpy array of shape (num_keypoints, 3)\n",
    "        title: string\n",
    "        figsize: tuple for figure size\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot point cloud\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], \n",
    "               c='lightblue', alpha=0.6, s=1, label='Point Cloud')\n",
    "    \n",
    "    # Plot keypoints\n",
    "    ax.scatter(keypoints[:, 0], keypoints[:, 1], keypoints[:, 2], \n",
    "               c='red', s=100, label='Predicted Keypoints', marker='o')\n",
    "    \n",
    "    # Add keypoint numbers\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        ax.text(kp[0], kp[1], kp[2], f'  {i}', fontsize=10)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    max_range = np.array([points[:, 0].max()-points[:, 0].min(),\n",
    "                         points[:, 1].max()-points[:, 1].min(),\n",
    "                         points[:, 2].max()-points[:, 2].min()]).max() / 2.0\n",
    "    mid_x = (points[:, 0].max()+points[:, 0].min()) * 0.5\n",
    "    mid_y = (points[:, 1].max()+points[:, 1].min()) * 0.5\n",
    "    mid_z = (points[:, 2].max()+points[:, 2].min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.view_init(elev=-90, azim=90)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict_points(model_path, input_ply, save = False):\n",
    "    predictor = KeypointPredictor(model_path)\n",
    "\n",
    "    mesh_path = input_ply \n",
    "    keypoints, points, metadata = predictor.predict_keypoints(mesh_path)\n",
    "\n",
    "    if keypoints is not None:\n",
    "        print(f\"Predicted {len(keypoints)} keypoints for {mesh_path}\")\n",
    "        print(\"Keypoints coordinates:\")\n",
    "        for i, kp in enumerate(keypoints):\n",
    "            print(f\"{kp[0]:.3f} {kp[1]:.3f} {kp[2]:.3f}\")\n",
    "\n",
    "        \n",
    "        # Visualize results\n",
    "        visualize_keypoints_3d(points, keypoints, f\"Keypoints for {os.path.basename(mesh_path)}\")\n",
    "        \n",
    "        # Save keypoints to file\n",
    "        if save:\n",
    "            output_path = mesh_path.replace('.ply', '_keypoints.txt')\n",
    "            save_keypoints_to_file(keypoints, output_path, mesh_path)\n",
    "    else:\n",
    "        print(f\"Failed to process {mesh_path}\")\n",
    "\n",
    "    \n",
    "\n",
    "predict_points(\"saved_models/kneenet++_4_5_final_2.pth\", \"scans_2/12252.stl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1242b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf6262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
